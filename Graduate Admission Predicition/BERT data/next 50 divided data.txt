I agree that the globalization of economic and communication networks will heighten international influences in all four of the areas listed.
However, while those influences will no doubt benefit education and the sciences, the nature of those influences on the arts and on politics will probably be a mixed one beneficial in some respects yet detrimental in others.

The dearest and most immediate beneficiaries of international influences are students. 
When students learn more about other cultures, systems of government, religions, and so forth, they advance their knowledge and grow in their understanding of humanity--which is, after all, the final objective of education. 
Emerging distance-learning technologies, made practicable now by the Internet, will no doubt carry an especially profound international influence on education. Distance learning will permit a class of students located all over the world to video-conference simultaneously with a teacher and with one other, thereby enlivening and enriching educational experiences.

The sciences dearly benefit from international influences as well. 
After all, principles of physics, chemistry, and mathematics know no political boundaries; thus a useful insight or discovery can come from a researcher or theorist anywhere in the world. 
Accordingly, any technology that enhances global communication can only serve to advance scientific knowledge. 
For example, astronomers can now transmit observational data to other scientists throughout the world the instant they receive that data, so that the entire global community of astronomers can begin interpreting that data together in a global brain-storming session. 
The sciences also benefit from multi-national economic cooperation. 
Consider, for instance, the multi-national program to establish a human colony on the Moon. 
This ambitious project is possible only because participating nations are pooling their economic resources as well as scientific talents.

With respect to the arts, however, the speaker's claim is far less convincing.
 It might seem that if artists broaden their cultural exposure and real-world experience their art works would become richer and more diverse. 
However, the logical consequence of increasing international influence on the arts is a homogenous global culture in which art becomes increasingly the same.
 The end result is not only a chilling effect on artistic creativity, but also a loss of cultural identity, which seems to be an important sociological and psychological need.

The impact of global networking on political relations might turn out to be a mixed one as well. 
Consider, for instance, the current unification of Europe's various monetary systems. Since Europe's countries are become economically interdependent, it would seem that it would be in their best interests to cooperate politically with one another. 
However, discord over monetary policy might result in member countries withdrawing from the Community, and in a political schism or other falling out. Consider also the burgeoning global communications network. 
On the one hand, it would seem that instant face-to-face communication between
diplomats and world leaders would help avert and quell political and military crises. By the same token, however, global networking renders any nation's security system more vulnerable. 
This point is aptly illustrated by a recent incident involving a high-ranking Pentagon official who stored top-secret fries on his home computer, which was connected to the Internet without any firewall precautions. 
Incidents such as this one might prompt the world's governments to become more protective of their sovereignty, more insular, and even-paranoid.

In sum, growing international influences that result naturally from global communications and economic networks can only serve to facilitate education and to advance scientific knowledge.
However, although the same influences no doubt will have an impact on the arts and on international politics, the speaker's claim that those influences will be beneficial is dubious, or at least premature, given that global networking is still in its nascent stages.

Should researchers focus on areas that are likely to result in the greatest benefit to the most people, as the speaker suggests?
 I agree insofar as areas of research certain to result in immediate and significant benefits for society should continue to be a priority. 
Yet, strictly followed, the speaker's recommendation would have a harmful chilling effect on research and new knowledge. 
This is particularly true in the physical sciences, as discussed below.

Admittedly, scientific research whose societal benefits are immediate, predictable, and profound should continue to be a high priority. 
For example, biotechnology research is proven to help cure and prevent diseases; advances in medical technology allow for safer, less invasive diagnosis and treatment; advances in genetics help prevent birth defects; advances in engineering and chemistry improve the structural integrity of our buildings, roads, bridges, and vehicles; information technology enables education; and communication technology facilitates global peace and participation in the democratic process. 
To demote any of these research areas to a lower priority would be patently foolhardy, considering their proven benefits to so many people. 
However, this is not to say that research whose benefits are less immediate or clear should be given lower priority. 
For three reasons, all avenues of scientific research should be afforded equal priority.
First of all, if we strictly follow the speaker's suggestion, who would decide which areas of research are more worthwhile than others? 
Researchers cannot be left to decide.
Given a choice, they will pursue their own special areas of interest, and it is highly unlikely that all researchers could reach a fully informed consensus as to what areas are most likely to help the most people. 
Nor can these decisions be left to regulators and legislators, who would bring to bear their own quirky notions about what is worthwhile, and whose susceptibility to influence-peddlers renders them untrustworthy in any event.

A telling example of the inherent danger of setting "official" research priorities involves the Soviet government's attempts during the 1920s to not only control the direction and the goals of its scientists' research but also to distort the outcome of that research--ostensibly for the greatest good of the greatest number of people. During the 1920s the Soviet government quashed certain areas of scientific inquiry, destroyed entire research facilities and libraries, and caused the sudden disappearance of many scientists who were viewed as threats the state's authority. Not surprisingly, during this time period no significant scientific advances occurred under the auspices of the Soviet government.

Secondly, to compel all researchers to focus only on certain areas would be to force many to waste their true talents. 
For example, imagine relegating today's preeminent astrophysicist Stephen Hawking to research the effectiveness of behavioral modification techniques in the reform of violent criminals. 
Admittedly, this example borders on hyperbole. 
Yet the aggregate effect of realistic cases would be to waste the intellectual talents of our world's researchers. 
Moreover, lacking genuine interest or motivation a researcher would be unlikely to contribute meaningfully to his or her "assigned" field.

Thirdly, it is difficult to predict which research avenues will ultimately lead to the greatest contributions to society. 
Research areas whose benefits are certain often break little new ground, and in the long term so-called "cutting-edge" research whose potential benefits are unknown often prove most useful to society. 
One current example involves terraforrning---creating biological life and a habitable atmosphere where none existed before.
 This unusual research area does not immediately address society's pressing social problems. 
Yet in the longer term it might be necessary to colonize other planets in order to ensure the survival of the human race; and after all, what could be a more significant contribution to society than preventing its extinction?

In sum, when it comes to setting priorities for research, at least in the sciences, the speaker goes too far by implying that research whose benefits are unknown are not worth pursuing. 
After all, any research worth doing delves into the unknown. In the final analysis, the only objective of research should be to discover truths, whatever they might be-- not to implement social policy.


The speaker claims that since so much in today's world is new and complex the past
provides little guidance for living in the present. 
I agree with this assertion insofar as history offers few foolproof panaceas for living today. 
However, I disagree with the speaker's claim that today's world is so unique that the past is irrelevant. 
One good example that supports my dual position is the way society has dealt with its pressing social problems over time.

Admittedly, history has helped us learn the appropriateness of addressing certain social issues, particularly moral ones, on a societal level. 
Attempts to legislate morality invariably fail, as illustrated by Prohibition in the 1930s and, more recently, failed federal legislation to regulate access to adult material via the Internet. 
We are slowly learning this lesson, as the recent trend toward legalization of marijuana for medicinal purposes and the recognition of equal rights for same-sex partners both demonstrate.

However, the only firm lesson from history about social ills is that they are here to stay. 
Crime and violence, for example, have troubled almost every society. All manner of reform, prevention, and punishment have been tried. 
Today, the trend appears to be away from reform toward a "tough-on-crime" approach. 
Is this because history makes clear that punishment is the most effective means of eliminating crime? 
No; rather, the trend merely reflects our current mores, attitudes, and political climate.

Another example involves how we deal with the mentally-iii segment of the population.
History reveals that neither quarantine, treatment, nor accommodation solves the problem, only that each approach comes with its own trade-offs. 
Also undermining the assertion that history helps us to solve social problems is the fact that, despite the civil-fights efforts of Martin Luther King and his progenies, the cultural gap today between African-Americans and white Americans seems to be widening. 
It seems that racial prejudice is a timeless phenomenon.

To sum up, in terms of how to live together as a society I agree that studying the past is of some value; for example, it helps us appreciate the futility of legislating morality. 
However, history's primary sociological lesson seems to be that today's social problems are as old as society itself, and that there are no panaceas or prescriptions for solving these problems---only alternate ways of coping with them.

What are the limits of our duty to save endangered species from extinction? 
The statement raises a variety of issues about morality, conscience, self-preservation, and economics. 
On balance, however, I fundamentally agree with the notion that humans need not make "extraordinary" efforts--at the expense of money and jobs--to ensure the preservation of any endangered species.

What are the limits of our duty to save endangered species from extinction? 
The statement raises a variety of issues about morality, conscience, self-preservation, and economics. 
On balance, however, I fundamentally agree with the notion that humans need not make "extraordinary" efforts--at the expense of money and jobs--to ensure the preservation of any endangered species.

As I see it, there are three fundamental arguments for imposing on ourselves at least some responsibility to preserve endangered species. 
The first has to do culpability.
According to this argument, to the extent that endangerment is the result of anthropogenic events such as dear-cutting of forests or polluting of lakes and streams, we humans have a duty to take affirmative measures to protect the species whose survival we've placed in jeopardy.

The second argument has to do with capability. 
This argument disregards the extent to which we humans might have contributed to the endangerment of a species. 
Instead, the argument goes, if we are aware of the danger, know what steps are needed to prevent extinction, and can take those steps, then we are morally obligated to help prevent extinction. 
This argument would place a very high affirmative duty on humans to protect endangered species.

The third argument is an appeal to self-preservation. 
The animal kingdom is an intricate matrix of interdependent relationships, in which each species depends on many others for its survival. 
Severing certain relationships, such as that between a predator and its natural prey, can set into motion a series of extinctions that ultimately might endanger our own survival as a species. 
While this claim might sound far-fetched to some, environmental experts assure us
that in the long run it is very real possibility.


On the other hand are two compelling arguments against placing a duty on humans to protect endangered species. 
The first is essentially the Darwinian argument that extinction results from the inexorable process of so-called “natural selection” in which stronger species survive while weaker ones do not. 
Moreover, we humans are not exempt from the process. 
Accordingly, if we see fit to eradicate other species in order to facilitate our survival, then so be it. 
We are only behaving as animal must, Darwin would no doubt assert.

The second argument, and the one that I find most compelling, is an appeal to logic over emotion. 
It is a scientific fact that thousands of animal species become extinct every year. Many such extinctions are due to natural forces, while others are due to anthropogenic factors.
 In any event, it is far beyond our ability to save them all. 
By what standard, then, should we decide which species are worth saving and which ones are not?
 In my observation, we tend to favor animals with human-like physical characteristics and behaviors. 
This preference is understandable; after all, dolphins are far more endearing than bugs. 
But there is no logical justification for such a standard. Accordingly, what makes more sense is to decide based on our own economic self-interest. 
In other words, the more money and jobs it would cost to save a certain species, the lower priority we should place on doing do.

In sum, the issue of endangered-species protection is a complex one, requiring subjective judgments about moral duty and the comparative value of various life forms. 
Thus, there are no easy or certain answers. 
Yet it is for this very reason I agree that economic self-interest should take precedence over vague notions about moral duty when it comes to saving endangered species.
 In the final analysis, at a point when it becomes critical for our own survival as a species to save certain others, then we humans will do so if we are fit – in accordance with Darwin’s observed process of natural selection.

Can we alter facts according to our wishes or inclinations? 
If by "facts" the speaker means such phenomena as political, economic, social, or legal status quo, then I concede that we can alter facts. 
The reason for this is that such systems are abstract constructs of our inclinations, wishes, and passions to begin with. 
Otherwise, I strongly agree with the speaker that we cannot alter facts. 
When it comes to certain aspect of our personal lives, and to historical events and scientific truths, no measure of desire or even passion can change external reality.
On an individual level, we all engage in futile attempts to alter facts--by pretending that certain things are not the way they are because they are inconsistent with our wishes or personal interests. 
Psychologists refer to this psychological defensive mechanism, which seems to be part of human nature, as "denial." 
Consider curious pastimes such as mind-reading, psychic healing, rituals that purportedly impart immortality, and other such endeavors, which seems to transcend all cultures and periods of human history. 
Understandably, we would all like to have the ability to alter the physical world, including ourselves, as we see fit, or even to live forever by means of the sheer force of our will. 
Yet, not one iota of scientific evidence lends support to the claim that any human being has ever had any such ability.

Nor can we alter facts by virtue of our inclinations or passions when it comes to history.
Admittedly, no person can truly know any particular past that the person did not experience firsthand.
 In this sense history is a construct, created for us by reporters, archivists, and historians. 
Historical facts are therefore susceptible to interpretation, characterization, and of course errors in commission and omission. 
This is not to say, however, that historical facts can be altered by our inventing versions that suit our inclinations or wishes. 
In short, an historical event is not rendered any less factual by either our ignorance or characterization of it.
Similarly, when it comes to science our wishes and desires ultimately yield to the
stubbornness of facts--by which I mean empirical scientific evidence and the laws and principles of the physical world. 
Admittedly, in many cases it is difficult to distinguish between scientific "fact" and mere "theory." 
History is replete with examples of what were considered at one time to be facts, but later disproved as incorrect theories. 
Yet it is telling that many such obsolete theories were based on the subjective inclinations, desires, and wishes of theorists and of the societies in which the theorists lived.
For example, the notions of an Earth-centered tmiverse and of linear time and space were both influenced by religious notions--that is, by human wishes and passions.
As our factual knowledge increased such theories ultimately give way.

In sum, I agree that facts are indeed "stubborn things." Understandably, all humans are guilty of ignoring, overlooking, and misunderstanding facts--at least to some extent. 
After all, human passion, desire, and individual bias and perspective are powerful influences when it comes to what we believe to be true and factual. 
Moreover, the statement carries deep epistemological implications regarding the nature of knowledge and truth, which I cannot begin to adequately address here. Nevertheless, on a less abstract level the speaker is correct that neither inclination, desire, nor passion, no matter how fervent, can alter that which is past or beyond our physical control.

I find the speaker's dual claim to be specious on both counts.
 The claim that society's destiny hinges on how children are socialized, while appealing in some respects, is an over-statement at best. 
And the claim that we have not yet learned how to raise children who can better society is poorly supported by empirical evidence.

Consider first the speaker's assertion that society's destiny depends on how children are socialized. 
I concede that unless a child is allowed sufficient opportunities for healthy interaction with peers, that child is likely to grow into an ineffectual, perhaps even an anti-sodal, adult. 
To witness healthy socialization in action, one need look no further than the school playground, where children learn to negotiate, cooperate, and assert themselves in a respectful manner, and where they learn about the harmful results of bullying and other anti-social behavior. 
These lessons help children grow up to be good citizens and effective leaders, as well as tolerant and respectful members of society.

However, socialization is only one factor influencing the extent to which an individual will ultimately contribute to a better society. 
And in my observation it is not the most important one. 
Consider certain prominent leaders who have contributed profoundly to a better society. 
Mahatma Gandhi's contributions sprang primarily from the courage of his inner convictions, in spite of his proper socialization among genteel Indian society and, as a law student, among British society. 
Martin Luther King's contribution was primarily the result of his strong religious upbringing, which had more to do with parental influence than with socialization. An even more remarkable modern example was Theodore Roosevelt, whose social and physical development were both stunted by life-threatening physical infirmities during his childhood. 
In spite of his isolation, odd manner and aloofness throughout his early life, Roosevelt ascended to a social-activist presidency by means of his will to overcome physical infLrmities, his voracious appetite for knowledge, and his raw intellect.

Consider next the speaker's claim that we have not yet learned how to raise children who can better society. 
If we define a "better" society as one characterized by greater tolerance of differing viewpoints and people who are different from ourselves, greater respect for individual rights, and greater cooperation across cultural and national boundaries, then the children of the most recent half-century are creating a better society. 
The most recent quarter-century has seen an increasing sensitivity in our society toward ensuring public health by policing the food and drug industries and by protecting our natural environment. 
We're becoming more sensitive to, and respectful of, the rights of women, various ethnic and racial groups, homosexuals, and mentally- and physically-challenged individuals. 
The re-emergence of political third parties with decidedly libertarian ideals demonstrates an increasing concern for individual freedoms. 
And there is ample evidence of increasing international cooperation. 
The former Soviet Union and the U.S. have worked coUaboratively in space research and exploration since the 1970s; peace-keeping missions are now largely multi-national efforts; and nations are now tackling public health problems coUaboratively through joint research programs. 
In short, the speaker's second claim flies in the face of the empirical evidence, as I see it.

In sum, when it comes to whether a child grows up to contribute to a better society, the key determinant is not socialization but rather some other factor--such as a seminal childhood event, parental influence, raw intelligence, or personal conviction. 
And, while reasonable people with differing political and social viewpoints might disagree about what makes for a "better" society, in my observation our society is steadily evolving into a more civilized, respectful, and tolerant one.
In the final analysis, then, I fundamentally disagree with both aspects of the speaker's dual claim.

The speaker asserts that the arts reveal society's hidden ideas and impulses. While this assertion has merit, I think it unfairly generalizes about art. 
Consider two particular art forms: architecture and painting. 
In more important architecture one consistently sees a refection of society's ideas and urges.
However, in more important paintings of the most recent century one sees instead the artists' personal and idiosyncratic visions of an aesthetic ideal.

Turning first to public architecture, one sees in ancient and Renaissance forms an
Impulse to transcend the human condition. 
Clearly, the most important architecture of these periods was built to honor deities and to propel humans into the afterlife. 
Consider, for example, the ancient pyramids and the great cathedrals of Europe, which rise upward toward the stars and heavens. 
During the Medieval period the most important architectural form was the castle, which reflected an overriding concern for military security and brute strength during a time of comparative anarchy. 
During the 20th Century it was first the steel-forged art deco forms and then the sky-scraping office building that dominated public architecture. 
These forms reflect modern, more mundane concerns for industrial and technological progress.

Turning next to important paintings and painters, it seems to me that the art of previous centuries reflected the attitudes and ideas of the prevailing culture to a far greater extent than today's art. 
The cynosures of the Medieval and Renaissance artists, for instance, were certain Christian themes--the Trinity, virgin birth of Christ, the Resurrection, and so forth with which the society at large was also preoccupied. 
Later, during the 18th and 19th Centuries, an emerging genteel class saw itself reflected in the bourgeois themes of impressionists such as Renoir and
Monet.

But in the most recent century the picture has been much different. Consider three of the 20th Century's most influential painters: Picasso, Dali and Pollock. 
Picasso's style underwent a series of radical changes throughout his career. 
Was the reason for Picasso's diverse "periods" a quick series of radical changes in society's ideas and impulses, or perhaps a reflection of society's hidden impulse for constant change? 
Or did Picasso's varied styles merely reflect the complex psychological profile of one eccentric artist? Dali is known for his surrealistic images; but do these images reveal some kind of existential angst on a societal level, or just the odd aesthetic vision of one man? 
Pollock's penchant was for dripping paint on the floor in order to create abstract images that would have the sort of visceral impact he was after.
 In fact, Pollock turned to this technique only after he tried but failed as a conventional painter, using brush and easel. 
So are Pollock's striking abstract murals a reflection of some mid-20th Century societal impulse, or merely the result of one struggling artist stumbling onto something he was good at?
In all three cases, it seems that the art reflected the artist but not the society.

In sum, in the art of painting one can observe a shift from styles and themes reflecting broad societal impulses to a more recent concern for expressing personal impulses and creative urges. 
In contrast, the more public art form of architecture has always mirrored society's ideas and impulses, and probably always will--because architecture is so much more public than the art of painting.

I strongly agree with the contention that absence of choice is a rare circumstance, primarily because this contention accords with common sense and our everyday experience as human beings. 
Besides, the reverse claim that we do not have free choice--serves to undermine the notions of moral accountability and human equality, which are critical to the survival of any democratic society.
Our collective life experience is that we make choices and decisions every day----on a continual basis. 
Common sense dictates that humans have free will, and therefore the true absence of choice is very rare. 
The only possible exceptions would involve extreme and rare circumstances such as solitary imprisonment or a severe mental or physical deficiency--any of which might potentially strip a person of his or her ability to make conscious choices. 
Yet even under these circumstances, a person still retains choices about voluntary bodily functions and movement.
 Thus the complete absence of choice would seem to be possible only in a comatose state or in death.

People often claim that life's circumstances leave them with "no choice." One might feel trapped in a job or a marriage. 
Under financial duress a person might claim that he or she has "no choice" but to declare bankruptcy, take a demeaning job, or even lie or steal to obtain money. 
The fundamental problem with these sorts of claims is that the claimants are only considering those choices that are not viable or attractive. 
That is, people in situations such as these have an infinite number of choices; it's just that many of the choices are unappealing, even self-defeating. 
For example, almost every person who claims to be trapped in a job is simply choosing to retain a certain measure of financial security. 
The choice to forego this security is always available, although it might carry unpleasant consequences.

Besides, the contention that we are almost invariably free to choose is far more appealing from a socio-political standpoint than the opposite claim. 
A complete lack of choice implies that every person's fate is determined, and that we all lack free will. 
According to the philosophical school of "strict determinism," every event, induding human actions and choices, that occurs is physically necessary given the laws of nature and events that preceded that event or choice. 
In other words, the "choices" that seem part of the essence of our being are actually beyond our control. 
Recent advances in molecular biology and genetics lend some credence to the determinists' position that as physical beings our actions are determined by physical forces beyond our control. 
New research suggests that these physical forces include our own individual genetic makeup.

However, the logical result of strict determinism and of the new "scientific determinism" is that we are not morally accountable for our actions and choices, even those that harm other individuals or society. 
Moreover, throughout history monarchs and dictators have embraced determinism, at least ostensibly, to bolster their claim that certain individuals are preordained to assume positions of authority or to rise to the top levels of the socioeconomic infrastructure.

Finally, the notion of scientific determinism opens the door for genetic engineering, which poses a potential threat to equality in socioeconomic opportunity, and could lead to the development of a so-caUed "master race." 
Admittedly, these disturbing implications neither prove nor disprove the determinists' claims. 
Nevertheless, assuming that neither free will nor determinism has been proven to be the correct position, the former is to be preferred by any humanist and in any democratic society.

In sum, despite the fact that we all experience occasional feelings of being trapped and having no choice, the statement is fundamentally correct. 
I would concede that science might eventually disprove the very notion of free will. However, until that time I'll trust my strong intuition that free will is an essential part of our being as humans and, accordingly, that humans are responsible for their own choices and actions.

The speaker contends that discovery and progress are made only through mistakes. I strongly agree with this contention, for two reasons. 
First, it accords with our personal experiences. 
Secondly, history informs us that on a societal level trial-and-error provides the very foundation for discovery and true progress, in all realms of human endeavor.

To begin with, the contention accords with our everyday experience as humans from early childhood through adulthood. 
As infants we learn how to walk by falling down again and again. 
As adolescents we discover our social niche, and develop self-confidence and assertiveness, only by way of the sorts of awkward social encounters that are part-and-parcel of adolescence. 
Through failed relationships not only do we discover who we are and are not compatible with, we also discover ourselves in the process. 
And, most of us find the career path that suits us only through trying jobs that don’t.

This same principle also applies on a societal level. Consider, for example, how we progress in our scientific knowledge. 
Our scientific method is essentially a call for progress through trial-and-error. 
Any new theory must be tested by empirical observation, and must withstand rigorous scientific scrutiny. 
Moreover, the history of theoretical science is essentially a history of trial-and-error. 
One modern example involves two contrary theories of physics: wave theory and quantum theory. 
During the last quarter-century scientists have been struggling to disprove one or the other--or to reconcile them. 
As it turns out, a new so-called "string" theory shows that the quantum and wave theories are mistakes in the sense that each one is inadequate to explain the behavior of all matter; yet both so-called "mistakes" were necessary for physics to advance, or progress, to this newer theory.

The value of trial-and-error is not limited to the sciences. 
In government and politics, progress usually comes about through dissension and challenge--that is, when people point out the mistakes of those in power.
 In fact, without our challenging the mistaken notions of established institutions, political oppression and tyranny would go unchecked. 
Similarly, in the fields of civil and criminal law, jurists and legislators who uphold and defend legal precedent must face continual opposition from those who question the fairness and relevance of current laws. 
This ongoing challenge is critical to the vitality and relevance of our system of laws.

In sum, the speaker correctly asserts that it is through mistakes that discovery and true progress are made. 
Indeed, our personal growth as individuals, as well as advances in science, government, and law, depends on making mistakes.


I strongly agree that great achievements often lead to great discontent. 
In fact, I would assert more specifically that great individual achievements can cause discontent for the individual achiever or for the society impacted by the achievement, or both. 
Never the- less, it is important to acknowledge that whether a great achievement causes great dis- content can depend on one's personal perspective, as well as the perspective of time.

With respect to individual achievements, great achievers are by nature ambitious people and therefore tend to be dissatisfied and discontent with their accomplishments—no matter how great. 
Great athletes are compelled to try to better their record-breaking per- formances; great artists and musicians typically daim that their greatest work will be their next one--a sign of personal discontent. 
And many child prot6g6s, especially those who achieve some measure of fame early in life, later suffer psychological discontent for having "peaked" so early. Perhaps the paradigmatic modern example of a great achiever's discontent was Einstein, whose theoretical breakthroughs in physics only raised new theoretical conundrums which Einstein himself recognized and spent the last twenty years of his life struggling unsuccessfully to solve.

Individual achievements can often result in discontent on a societal level. 
The great achievement of the individual scientists responsible for the success of the Manhattan Project resulted in worldwide anxiety over the threat of nuclear annihilation--a form of discontent with which the world's denizens will forever be forced to cope. 
Even individual achievements that at first glance would appear to have benefited society turn out to be causes of great discontent. 
Consider the invention of the automobile, along with the innovations in manufacturing processes and materials that made mass production possible. 
As a result we have become a society enslaved to our cars, relying on them as crutches not only for transportation but also for affording us a false sense of socioeconomic status. 
Moreover, the development of assembly-line manufacturing has served to alienate workers from their work, which many psychologists agree causes a great deal of personal discontent.

Turning from individual achievements to societal, induding political, achievements, the extent to which great achievements have caused great discontent often depends on one's perspective. 
Consider, for example, America's spirit of Manifest Destiny during the 19th Century, or British Imperialism over the span of several centuries. 
The perspective of an Imperialist, conquering other lands and peoples might be viewed as an unqualified success. 
However, from the viewpoint of the indigenous peoples who suffer at the hands of Imperialists, these so-called "achievements" are the source of widespread oppression and misery, and in turn discontent, to which any observant Native American or South African native could attest.

The extent to which great socio-political achievements have caused great discontent also depends on the perspective of time. 
For example, F.D.R.'s New Deal was and still is considered by many to be one of the greatest social achievements of the 20th Century. 
However, we are just now beginning to realize that the social-security system that was an integral part of F.D.R.'s social program will soon result in great discontent among those workers currently paying into the system but unlikely to see any benefits after they retire.

To sum up, I agree that great achievements, both individual and socio-political, often result in great discontent. 
Moreover, great individual achievements can result in discontent for both the individual achiever and the society impacted by the achievement. 
Nevertheless, in measuring the extent of discontent, we must account for varying personal and political perspectives as well as different time perspectives.

This statement asserts that art, not the art critic, provides something of lasting value to society. 
I strongly agree with the statement. Although the critic can help us understand and appreciate art, more often than not, critique is either counterproductive to achieving the objective of art or altogether irrelevant to that objective.
To support the statement the speaker might point out the three ostensible functions of the art critic. 
First, critics can help us understand and interpret art; a critic who is familiar with a particular artist and his or her works might have certain insights about those works that the layperson would not. 
Secondly, a critic's evaluation of an art work serves as a filter, which helps us determine which art is worth our time and attention. 
For example, a new novel by a best-selling author might nevertheless be an uninspired effort, and if the critic can call our attention to this fact we gain time to seek out more worthwhile literature to read. 
Thirdly, a critic can provide feedback for artists; and constructive criticism, if taken to heart, can result in better work.

However, reflecting on these three functions makes clear that the art critic actually offers very little to society. 
The first function is better accomplished by docents and teachers, who are more able to enhance a layperson's appreciation an understanding of art by providing an
objective, educated interpretation of it. 
Besides, true appreciation of art occurs at the moment we encounter art; it is the emotional, even visceral impact that art has on our senses, spirits, and souls that is the real value of art. 
A critic can actually provide a disservice by distracting us from that experience.

The critic's second function that of evaluator who filters out bad art from the worthwhile is that we must be very wary of. 
History supports this caution. In the role of judge, critics have failed us repeatedly. Consider, for example, Voltaire's rejection of Shakespeare as barbaric because he did not conform to neo-classical principles of unity. 
Or, consider the complete dismissal of Beethoven's music by the esteemed critics of his 6me. 
The art critic's judgment is limited by the narrow confines of old and established parameters for evaluation. 
Moreover, critical judgment is often misguided by the ego; thus its value is questionable in any event.
I turn finally to the critic's third function: to provide useful feedback to artists. 
The value of this function is especially suspect. 
Any artist, or anyone who has studied art, would agree that true art is the product of the artist's authentic passion, a manifestation of the artist's unique creative impulse, and a creation of the artist's spirit. 
If art were shaped by the concern for integrating feedback from ali criticism, it would become a viable craft, but at the same time would cease to be art.
In sum, none of the ostensible functions of the critic are of much value at all, let alone of lasting value, to society. 
On the other hand, the artist, through works of art, provides an invaluable and unique mirror of the culture of the time during which the work was produced a mirror for the artist's contemporaries and for future generations to gaze into for insight and appreciation of history. 
The art critic in a subordinate role, more often than not, does a disservice to society by obscuring this mirror.

Personal economic success might be due either to one's investment strategy or to one's work or career. 
With respect to the former, non-conformists with enough risk tolerance and patience invariably achieve more success than conformists. 
With respect to the latter, while non-conformists are more likely to succeed in newer industries where markets and technology are in constant flux, conformists are more likely to succeed in traditional service industries ensconced in systems and regulations.

Regarding the sort of economic success that results from investing one's wealth, the principles of investing dictate that those who seek risky investments in areas that are out of favor with the majority of investors ultimately reap higher returns than those who follow the crowd. 
It is conformists who invest, along with most other investors, in areas that are currently the most profitable, and popular. 
However, popular investments tend to be overpriced, and in the long run their values will come down to reasonable levels. 
As a result, given enough time conformists tend to reap lower rewards from their investments than nonconformists do.

Turning to the sort of economic success that one achieves by way of one's work, neither conformists nor non-conformists necessarily achieve greater success than the other group.
 In consumer-driven industries, where innovation, product differentiation and creativity are crucial to lasting success, non-conformists who take unique approaches tend to recognize emerging trends and to rise above their peers. 
For example, Ted Tumer's departure from the traditional format of the other television networks, and the responsiveness of Amazon's Jeff Bezos to burgeoning Internet commerce, propelled these two non-conformists into leadership positions
in their industries. 
Particularly in technology industries, where there are no conventional practices or ways of thinking to begin with, people who cling to last year's paradigm, or to the status quo in general, are soon left behind by coworkers and competing firms.

However, in traditional service industries--such as fnance, accounting, insurance, legal services, and health care--personal economic success comes not to non-conformists but rather to those who can work most effectively within the constraints of established practices, policies and regulations. 
Of course, a clever idea for structuring a deal, or a creative legal maneuver, might play a role in winning smaller battles along the way. 
But such tac-tics are those of conformists who are playing by the same ground rules as their peers; winners are just better at the game.

In conclusion, non-conformists with sufficient risk tolerance and patience are invariably the most successful investors in the long run. 
When it comes to careers, however, while non-conformists tend to be more successful in technology- and consumer-driven industries, traditionalists are the winners in system-driven industries pervaded by policy, regulation, and bureaucracy.

The speaker asserts that when many people question authority society is better off. While I contend that certain forms of disobedience can be harmful to any society, I agree with the speaker otherwise. 
In fact, I would go further by contending that society's well-being depend on challenges to authority, and that when it comes to political and legal authority, these challenges must come from many people.

Admittedly, when many people question authority some societal harm might result, even if a social cause is worthy. 
Mass resistance to authority can escalate to violent protest and rioting, during which innocent people are hurt and their property damaged and destroyed. 
The fallout from the 1992 Los Angeles riots aptly illustrates this point. 
The "authority" which the rioters sought to challenge was that of the legal justice system which acquitted police officers in the beating of Rodney King. 
The means of challenging that authority amounted to flagrant disregard for criminal law on a mass scale--by way of looting, arson, and even deadly assault.
This violent challenge to authority resulted in a financially crippled community and, more broadly, a turning back of the clock with respect to racial tensions across America.

While violence is rarely justifiable as a means of questioning authority, peaceful challenges to political and legal authority, by many people, are not only justifiable but actually necessary when it comes to enhancing and even preserving society's well-being. 
In particular, progress in human rights depends on popular dissension. 
It is not enough for a charismatic visionary like Gandhi or King to call for change in the name of justice and humanity; they must have the support of many people in order to effect change.
 Similarly, in a democracy citizens must respect timeless legal doctrines and principles, yet at the same time question the fairness and relevance of current laws. Otherwise, our laws would not evolve to reflect changing societal
values. 
It is not enough for a handful of legislators to challenge the legal status quo; ultimately it is up to the electorate at large to call for change when change is needed for the well-being of society.

Questioning authority is also essential for advances in the sciences. 
Passive acceptance of prevailing principles quells innovation, invention, and discovery, all of which clearly benefit any society. 
In fact, the very notion of scientific progress is predicated on rigorous scientific inquiry--in other words, questioning of authority. 
History is replete with scientific discoveries that posed challenges to political, religious, and scientific authority. 
For example, the theories of a sun-centered solar system, of humankind's evolution from other life forms, and of the reactivity of time and space, clearly flew in the face of "authoritative" scientific as well as religious doctrine of their time. Moreover, when it comes to science a successful challenge to authority need not come from a large number of people. 
The key contributions of a few individuals---like Copernicus, Kepler, Newton, Darwin, Einstein, and Hawking---often suffice.

Similarly, in the arts, people must challenge established styles and forms rather than imitate them; otherwise, no geminal new art would ever emerge, and society would be worse off. 
And again, it is not necessary that a large number of people pose such challenges; a few key individuals can have a profound impact. 
For instance, modern ballet owes much of what is new and exciting to George Ballanchine, who by way of his improvisational techniques posed a successful challenge to established traditions. 
And modern architecture arguably owes its existence to the founders of Germany's Bauhaus School of Architecture, which challenged certain "authoritative" notions about the proper objective, and resulting design, of public buildings.

To sum in general I agree that when many people question authority the well-being of society is enhanced. 
Indeed, advances in government and law depend on challenges to the status quo by many people. 
Nevertheless, to ensure a net benefit rather than harm, the means of such challenges must be peaceful ones.

This statement asserts that art, not the art critic, provides something of lasting value to society. 
I strongly agree with the statement. 
Although the critic can help us understand and appreciate art, more often than not, critique is either counterproductive to achieving the objective of art or altogether irrelevant to that objective.

To support the statement the speaker might point out the three ostensible functions of the art critic.
 First, critics can help us understand and interpret art; a critic who is familiar with a particular artist and his or her works might have certain insights about those works that the layperson would not. 
Secondly, a critic's evaluation of an art work serves as a filter, which helps us determine which art is worth our time and attention. 
For example, a new novel by a best-selling author might nevertheless be an uninspired effort, and if the critic can call our attention to this fact we gain time to seek out more worthwhile literature to read. 
Thirdly, a critic can provide feedback for artists; and constructive criticism, if taken to heart, can result in better work.

However, reflecting on these three functions makes clear that the art critic actually offers very little to society. 
The first function is better accomplished by docents and teachers, who are more able to enhance a layperson's appreciation and understanding of art by providing an objective, educated interpretation of it. 
Besides, true appreciation of art occurs at the moment we encounter art; it is the emotional, even visceral impact that art has on our senses, spirits, and souls that is the real value of art. 
A critic can actually provide a disservice by distracting us
from that experience.


The critic's second function that of evaluator who filters out bad art from the worthwhile is one that we must be very wary of. 
History supports this caution. In the role of judge, critics have failed us repeatedly. Consider, for example, Voltaire's rejection of Shakespeare as barbaric because he did not conform to neo-classical principles of unity. 
Or, consider the complete dismissal of Beethoven's music by the esteemed critics of his 6me. 
The art critic's judgment is limited by the narrow confines of old and established parameters for evaluation. 
Moreover, critical judgment is often misguided by the ego; thus its value is questionable in any event.
I turn finally to the critic's third function: to provide useful feedback to artists. The value of this function is especially suspect. 
Any artist, or anyone who has studied art, would agree that true art is the product of the artist's authentic passion, a manifestation of the artist's unique creative impulse, and a creation of the artist's spirit. 
If art were shaped by the concern for integrating feedback from ali criticism, it would become a viable craft, but at the same time would cease to be art.
In sum, none of the ostensible functions of the critic are of much value at all, let alone of lasting value, to society.
 On the other hand, the artist, through works of art, provides an invaluable and unique mirror of the culture of the time during which the work was produced a mirror for the artist's contemporaries and for future generations to gaze into for insight and appreciation of history. 
The art critic in a subordinate role, more often than not, does a disservice to society by obscuring this mirror.

The speaker claims that people who are the most fmnly committed to an idea or policy are the same people who are most critical of that idea or policy. 
While I find this claim paradoxical on its face, the paradox is explainable, and the explanation is well supported empirically. 
Nevertheless, the claim is an unfair generalization in that it fails to account for other empirical evidence serving to discredit it.

A threshold problem with the speaker's claim is that its internal logic is questionable. 
At first impression it would seem that firm commitment to an idea or policy necessarily requires the utmost confidence in it, and yet one cannot have a great deal of confidence in an idea or policy if one recognizes its flaws, drawbacks, or other problems. 
Thus commitment and criticism would seem to be mutually exclusive. 
But are they? 
One possible explanation for the paradox is that individuals most fmnly committed to an idea or policy are often the same people who are most knowledgeable on the subject, and therefore are in the best position to understand and appreciate the problems with the idea or policy.

Lending credence to this explanation for the paradoxical nature of the speaker's claim are the many historical cases of uneasy marriages between commitment to and criticism of the same idea or policy. 
For example, Edward Teller, the so-called "father of the atom bomb," was firmly committed to America's policy of gaining military superiority over the Japanese and the Germans; yet at the same time he attempted fervently to dissuade the U.S. military from employing his technology for destruction, while becoming the most visible advocate for various peaceful and productive applications of atomic energy. Another example is George Washington, who was quoted as saying that all the world's denizens "should abhor war wherever they may find it." 
Yet this was the same military general who played a key role in the Revolutionary War between Britain and the States. 
A third example was Einstein, who while committed to the mathematical soundness of his theories about relativity could not reconcile them with the equally compelling quantum theory which emerged later in Einstein's life. 
In fact, Einstein spent the last twenty years of his life criticizing his own theories and struggling to determine how to reconcile them with newer theories.

In the face of historical examples supporting the speaker's claim are innumerable influential individuals who were zealously committed to certain ideas and policies but who were not critical of them, at least not outwardly. 
Could anyone honestly claim, for instance, that Elizabeth Stanton and Susan B. Anthony, who in the late 19th Century paved the way for the women's rights movement by way of their fervent advocacy, were at the same time highly critical or suspicious of the notion that women deserve equal rights under the law?
 Also, would it not be absurd to claim that Mahatma Gandhi and Martin Luther King, history's two leading advocates of civil disobedience as a means to social reform, had serious doubts about the ideals to which they were so demonstrably committed? 
Finally, consider the two ideologues and revolutionaries Lenin and Mussolini. 
Is it even plausible that their demonstrated commitment to their own Communist and Fascist policies, respectively, belied some deep personal suspicion about the merits of these policies? 
To my knowledge no private writing of any of these historical figures lends any support to the claim that these leaders were particularly critical of their own ideas or policies.

To sum up, while at first glance a deep commitment to and incisive criticism of the same idea or policy would seem mutually exclusive, it appears they are not. 
Thus the speaker's claim has some merit. 
Nevertheless, for every historical case supporting the speaker's claim are many others serving to refute it. In the final analysis, then, the correctness of the speaker's assertion must be determined on a case-by-case basis.

Must we choose between tradition and modernization, as the speaker contends.; I agree that in certain cases the two are mutually exclusive. 
For the most part, however, modernization does not reject tradition; in fact, in many cases the former can and does embrace the latter.

In the first place, oftentimes so-caUed "modernization" is actually an extension or new iteration of tradition, or a variation on it. 
This is especially true in language and in law. 
The modern English language, in spite of its many words that are unique to modern Western culture, is derived from, and builds upon, a variety of linguistic traditions--and ultimately from the ancient Greek and Latin languages. 
Were we to insist on rejecting traditional in favor of purely modern language, we would have essentially nothing to say. 
Perhaps an even more striking marriage of modernization and tradition is our system of laws in the U.S., which is deeply rooted in English common-law principles of equity and justice. 
Our system requires that new, so-called "modern" laws be consistent with, and in fact build upon, those principles.

In other areas modernization departs from tradition in some respects, while embracing it in others. 
In the visual arts, for example, "modern" designs, forms, and elements are based on certain timeless aesthetic ideals--such as symmetry, balance, and harmony. 
Modern art that violates these principles might hold ephemeral appeal due to its novelty and brashness, but its appeal lacks staying power. 
An even better example from the arts is modern rock-and-roll music, which upon first listening might seem to bear no resemblance to classical music traditions. 
Yet, both genres rely on the same twelve-note scale, the same notions of what
harmonies are pleasing to the ear, the same forms, the same rhythmic meters, and even many of the same melodies.

I concede that, in certain instances, tradition must yield entirely to the utilitarian needs of modern life. 
This is true especially when it comes to architectural traditions and the value of historic and archeological artifacts. 
A building of great historic value might be located in the only place available to a hospital desperately needing additional parking area. 
An old school that is a prime example of a certain architectural style might be so structurally unsafe that the only practicable way to remedy the problem would be to raze the building to make way for a modern, structurally sound one. 
And when it comes to bridges whose structural integrity is paramount to public safety, modernization often requires no less than replacement of the bridge altogether. 
However, in other such cases architecturally appropriate retrofits can solve structural problems without sacrificing history and tradition, and alternative locations for new buildings and bridges can be found in order to preserve tradition associated with our historic structures. 
Thus, even in architecture, tradition and modernization are not necessarily mutually exclusive options.

To sum up, in no area of human endeavor need modernization supplant, reject, or otherwise exclude tradition. 
In fact, in our modern structures, architecture and other art, and especially languages and law, tradition is embraced, not shunned.

The speaker asserts that television and computer connectivity will soon render tourism obsolete. 
I agree that these technologies might eventually serve to reduce travel for certain purposes other than tourism. 
However, I strongly disagree that tourism will become obsolete, or that it will even decline, as a result.

As for the claim that television will render tourism obsolete, we already have sufficient empirical evidence that this will simply not happen. 
For nearly a half-century we have been peering through our television sets at other countries and cultures; yet tourism is as popular today as ever. 
In fact, tourism has been increasing sharply during the last decade, which has seen the advent of television channels catering exclusively to our interest in other cultures and countries. 
The more reasonable conclusion is that television has actually served to spark our interest in visiting other places.

It is somewhat more tempting to accept the speaker's further claim that computer
connectivity will render tourism obsolete. 
However, the speaker unfairly assumes that the purpose of tourism is simply to obtain information about other people and places. 
Were this the case, I would entirely agree that the current information explosion spells the demise of tourism. 
But, tourism is not primarily about gathering information. 
Instead, it is about sensory experience--seeing and heating firsthand, even touching and smelling. 
Could anyone honestly claim that seeing a picture or even an enhanced 3-D movie of the Swiss Alps serves as a suitable substitute for riding a touting motorcycle along narrow roads traversing those mountains? 
Surely not. 
The physical world is laden with a host of such delights that we humans are compelled to experience firsthand as tourists.

Moreover, in my view tourism will continue to thrive for the same reason that people still go out for dinner or to the movies: we all need to "get away" from our familiar routines and surroundings from time to 6me. 
Will computer connectivity alter this basic need? Certainly not. 
In short, tourism is a manifestation of a basic human need for variety and for exploration. 
This basic need is why humans have come to inhabit every corner of the Earth, and will just as surely inhabit other planets of the solar system.

In fact, computer connectivity might actually provide a boon for tourism. 
The costs of travel and accommodations are likely to decrease due to Internet price competition. 
Even more significantly, to the extent that the Internet enhances communication among the world's denizens, our level of comfort and trust when it comes to dealing with people from other cultures will only increase. 
As a result, many people who previously would not have felt safe or secure traveling to strange lands will soon venture abroad with a new sense of confidence.

Admittedly, travel for purposes other than tourism might eventually decline, as the business world becomes increasingly dependent on the Internet. 
Products that can be reduced to digital "bits and bites" can now be shipped anywhere in the world without any human travel. 
And the volume of business-related trips will surely decline in the future, as teleconferencing becomes more readily available.
 To the extent that business travelers "play tourist" during business trips, tourism will decline as a result. 
Yet it would be absurd to claim that these phenomena alone will render tourism obsolete.

In sum, while business travel might decline as a result of global connectivity, tourism is likely to increase as a result. 
Global connectivity, especially the Internet, can only pique our curiosity about other peoples, cultures, and places. 
Tourism helps satisfy that curiosity, as well as satisfying a fundamental human need to experience new things first-hand and to explore the world.

Do high-speed means of communication, particularly television and computers, tend to prevent meaningful and thoughtful communication, as the speaker suggests? 
Although ample empirical evidence suggests so with respect to television, the answer is far less dear when it comes to communication via computers.

Few would argue that since its inception broadcast television has greatly enhanced
communication to the masses. 
The circulation of even the most widely read newspapers pales compared to the number of viewers of popular television news programs. 
Yet traditional television is a one-way communications medium, affording viewers no opportunity to engage those so-called "talking heads" in dialogue or respond. 
Of course, there is nothing inherent about television that prevents us from meaningful and thoughtful communication with each other. 
In fact, in television's early days it was a fairly common occurrence for a family to gather around the television together for their favorite show, then afterwards discuss among themselves what they had seen and heard. 
Yet over time television has proven itself to serve primarily as a baby-sitter for busy parents, and as an means of escape for those who wish to avoid communicating with the people around them. 
Moreover, in the pursuit of profit, network executives have determined over time that the most effective uses of the medium are for fast-paced entertainment and advertising--whose messages are neither thoughtful nor meaningful.

Do computers offer greater promise for thoughtful and reflective communication than television? Emphatically, yes. 
After all, media such as email and the Web are interactive by design. 
And the opportunity for two-way communication enhances the chances of meaningful and thoughtful communication. 
Yet their potential begs the question: Do these media in fact serve those ends? 
It is tempting to hasten that the answer is "yes" with respect to email; after are, we've all heard stories about how email has facilitated reunions of families and old friends, and new long-distance friendships and romances. 
Moreover, it would seem that two-way written communication requires far more thought and reflection than verbal conversation. 
Nevertheless, email is often used to avoid face-to-face encounters, and in practice is used as a means of distributing quick memos. 
Thus on balance it appears that email serves as an impediment, not an aide, to thoughtful and reflective communication. 
With respect to Web-based communication, the myriad of educational sites, interactive and otherwise, is strong evidence that the Web tends to enhance, rather than prevent, meaningful communication. 
Distance learning courses made possible by the Web lend further credence to this assertion. 
 Nonetheless, by all accounts it appears that the Web will ultimately devolve into
a mass medium for entertainment and for e-commerce, just like traditional television. 
Meaningful personal interactivity is already yielding to advertising, requests for product information, buy-seU orders, and titillating adult-oriented content.

Thus, on balance these high-speed electronic media do indeed tend to prevent rather than facilitate meaningful and thoughtful communication. 
In the final analysis, any mass medium carries the potential for uplifting us, enlightening us, and helping us to communicate with and understand one another. However, by all accounts, television has not fulfilled that potential; and whether the Web will serve us any better is ultimately up to us as a society.

The speaker actually raises two distinct issues here: (1) whether information can eliminate, or at least help reduce, prejudice; and (2) if not, whether this is because prejudice is rooted in emotion rather than reason. 
Despite the evidence to the contrary, I fundamentally agree with the speaker's essential claim that prejudice is here to stay because it is firmly rooted in emotion rather than reason.
Regarding the first issue, it would appear at first glance that prejudice is declining as a result of our becoming a more enlightened, or better informed, society. 
During the past quarter-decade, more so than any other period in human history, various voices of reason have been informing us that racial, sexual, and other forms of prejudice are unfounded in reason, morally wrong, and harmful to any society. During the 1960s and 1970s such information came from civil-rights and feminist activists; more recently the primary source of this information has been mainstream media, which now affirmatively touts the rights of various racial groups, women, and homosexuals. 
Moreover, increasing mobility and cultural awareness surely serve to inform people the world over that we are all essentially alike.

It would seem that, as a result of this flood of information, we would be making clear progress toward eliminating prejudice. 
However, much of this so-called progress is forced upon us legislatively--in the form of anti-discrimination laws in the areas of employment, housing, and education, which now protect all significant minority groups. 
Without these laws, would we voluntarily refrain from the discriminatory behavior and other forms of prejudice that the laws prevent? Perhaps not.

Moreover, signs of prejudice are all around us today. 
Extreme factions still rally around bigoted demagogues; the number of "hate crimes" is increasing alarmingly; and the cultural gap between white Americans and African-Americans seems to be widening as the level of mutual distrust heightens. Besides, what appears to be respect for one another's differences may in fact be an increasing global homogeneity--that is, we are becoming more and more alike.
 In short, on a societal level an apparent decline of prejudice is actually legislated morality and increasing homogeneity. 
Accordingly, I find the speaker's threshold assertion--that no
amount of information can eliminate prejudice-- compelling indeed.

The second issue that the statement raises is whether prejudice is learned or instinctive. 
If it were learned, then it would seem that by obtaining certain information, or by purging one's mind of certain dis-information, one could learn to not be prejudiced. Despite popular notions that this is possible, I have my doubts because these are age-old theories but we see little evidence that prejudice is on the wane. 
Thus it seems that the root of prejudice lies more in an instinctive, almost primal, sense of fear than in the sort of distrust that is learned and can therefore be "unlearned."
 Accordingly, I also find the speaker's second assertion—that prejudice is rooted in emotion---compelling as well.

In sum, despite a deluge of information debunking our false notions about people who are different than us, as a society it appears we have not reversed our inclination toward prejudice. 
Therefore, I find convincing the speaker's claim that prejudice is rooted in the sort of emotion that reason cannot override.

Should the only responsibility of a business executive be to maximize business profits, within the bounds of the law?
 In several respects this position has considerable merit; yet it ignore certain compelling arguments for imposing on businesses additional obligations to the society in which they operate.

On the one hand are two convincing arguments that profit maximization within the bounds of the law should be a business executive's sole responsibility. 
First, imposing on businesses additional duties to the society in which they operate can, paradoxically, harm that society. 
Compliance with higher ethical standards than the law requires--m such areas as environmental impact and workplace conditions--adds to business expenses and lower immediate profits. 
In turn, lower profits can prevent the socially conscious business from creating more jobs, and from keeping its prices low and the quality of its products and services  high.
 Thus if businesses go further than their legal duties in serving their communities the end result might be a net disservice to those communities.

Secondly, by affirming that profit maximization within legal bounds is the most ethical behavior possible for business, we encourage private enterprise, and more individuals enter the marketplace in the quest of profits. 
The inevitable result of increased competition is lower prices and better products, both of which serve the interests of consumers.
 Moreover, since maximizing profits enhances the wealth of a company's stakeholders, broad participation in private enterprise raises the wealth of a nation, expands its economy, and raises its overall standard of living and quality of life.

On the other hand are three compelling arguments for holding business executives to certain responsibilities m addition to profit maximization and to compliance with the letter of the law. 
First, a growing percentage of businesses are related to technology, and haws often lag behind advances in technology. 
As a result, new technology-based products and services might pose potential harm to consumers even though they conform to current laws. 
For example, Internet commerce is still largely unregulated because our lawmakers are slow to react to the paradigm shift from brick-and-mortar commerce to e-commerce. 
As a result, unethical marketing practices, privacy invasion, and violations of intellectual-property rights are going unchecked for lack of regulations that would clearly prohibit them.

Secondly, since a nation's laws do not extend beyond its borders, compliance with those laws does not prevent a business from doing harm elsewhere. 
Consider, for example, the trend among U.S. businesses in exploiting workers in countries where labor laws are virtuaUy non-existent in order to avoid the costs of complying with U.S. labor laws.

Thirdly, a philosophical argument can be made that every business enters into an implied social contract with the community that permits it to do business, and that this social contract, although not legally enforceable, places a moral duty on the business to refrain from acting in ways that will harm that community.

In sum, I agree with the statement insofar as in seeking to maximize profits a business serves not only itself but also its employees, customers, and the overall economy. 
Yet today's rapidly changing business environment and increasing globalization call for certain affirmative obligations beyond the pursuit of profit and mere compliance with enforceable rules and regulations. 
Moreover, in the final analysis any business is indebted to the society in which it operates for its very existence, and thus has a moral duty, regardless of any legal obligations, to pay that debt.

The speaker contends that students should be skeptical in their studies, and should not accept passively whatever they are taught.
 In my view, although undue skepticism might be counterproductive for a young child's education, I strongly agree with the speaker otherwise. 
Ifwe were all to accept on blind faith all that we are taught, our society would never progress or evolve

Skepticism is perhaps most important in the physical sciences. Passive acceptance or prevailing principles quells innovation, invention, and discovery.
 In fact, the very notion of scientific progress is predicated on rigorous scientific inquiry--in other words, skepticism. 
And history is replete with examples of students of science who challenged what they had been taught, thereby paving the way for scientific progress. 
For example, in challenging the notion that the Earth was in a fixed position at the center of the universe, Copernicus paved the way for the corroborating observations of Galileo a century later, and ultimately for Newton's principles of gravity upon which all modern science is based. The staggering cumulative impact of Copernicus' rejection of what he had been taught is proof enough of the value of skepticism.

The value of skepticism is not limited to the physical sciences, of course. 
In the fields of sociology and political science, students must think critically about the assumptions underlying the status quo; otherwise, oppression, tyranny and prejudice go unchecked. 
Similarly, while students of the law must learn to appreciate timeless legal doctrines and principles, they must continually question the fairness and relevance of current laws. Otherwise, our laws would not evolve to reflect changing societal values and to address new legal issues arising from our ever-evolving technologies.

Even in the arts, students must challenge established styles and forms rather than learn to imitate them; otherwise, no genuinely new art would ever emerge. 
Bee-bop musicians such as Charlie Parker demonstrated through their wildly innovative harmonies and melodies their skepticism about established rules for harmony and melody. 
In the area of dance BaUanchine showed by way of his improvisational techniques his skepticism about established rules for choreography. 
And Germany's Bauhaus School of Architecture, to which modern architecture owes its existence, was rooted in skepticism about the proper objective, and resulting design, of public buildings.

Admittedly, undue skepticism might be counterproductive in educating young children. 
I am not an expert in developmental psychology; yet observation and common sense informs me that youngsters must first develop a foundation of experiential knowledge before they can begin to think critically about what they are learning. 
Even so, in my view no student, no matter how young, should be discouraged from asking "Why?" and "Why not?" 

To sum up, skepticism is the very stuff that progress is made of, whether it be in science, sociology, politics, the law, or the arts. 
Therefore, skepticism should be encouraged at all but the most basic levels of education.

Should parents and communities participate in local education because education is too important to leave to professional educators, as the speaker asserts? 
It might be tempting to agree with the speaker, based on a parent's legal authority over, familiarity with, and interest in his or her own children. 
However, a far more compelling argument can be made that, except for major decisions such as choice of school, a child's education is best left to professional educators.

Communities of parents concerned about their children's education rely on three arguments for active parental and community participation in that process. 

The first argument, and the one expressed most often and vociferously, is that parents hold the ultimately legal authority to make key decisions about what and how their own children learn including choice of curriculum and text books, pace and schedule for learning, and the extent to which their child should learn alongside other children. 
The second argument is that only a parent can truly know the unique needs of a child including what educational choices are best suited for the child. 
The third argument is that parents are more motivated--by pride and ego--than any other person to take whatever measures are needed to ensure their children receive the best possible education.

Careful examination of these three arguments, however, reveals that they are specious at best. 
As for the first one, were we to allow parents the right to make all major decisions regarding the education of their children, many children would go with little or no education. 
In a perfect world parents would always make their children's education one of their highest priorities. 
Yet, in fact many parents do not. 
As for the second argument, parents are not necessarily best equipped to know what is best for their child when it comes to education.

Although most parents might think they are sufficiently expert by virtue of having gone through formal education themselves, parents lack the specialized training to appreciate what pedagogical methods are most effective, what constitutes a balanced education, how developmental psychology affects a child's capacity for learning at different levels and at different stages of childhood. 
Professional educators, by virtue of their specialized training in these areas, are far better able to ensure that a child receives a balanced, properly paced education.

There are two additional compelling arguments against the speaker's contention. First, parents are too subjective to always know what is truly best for their children. For example, many parents try to overcome their own shortcomings and failed self-expectations vicariously through their children's accomplishments. 
Most of us have known parents who push their child to excel in certain areas--to the emotional and psychological detriment of the child. 
Secondly, if too many parties become involved in making decisions about day-to-day instruction, the end result might be infighting, legal battles, boycotts, and other protests, all of which impede the educational process; and the ultimate victims are the children themselves.
 Finally, in many jurisdictions parents now have the option of schooling their children at home, as long as certain state requirements are met. 
In my observation, home schooling allows parents who prefer it great control over a child's education, while allowing the professional educators to discharge their responsibilities as effectively as possible--unfettered by gadfly parents who constantly interfere and intervene.
In sum, while parents might seem better able and better motivated to make key decisions about their child's education, in many cases they are not. 
With the possible exceptions of responsible home-schoolers, a child's intellectual, social, and psychological development is at risk when communities of parents dominate the decision-making process involving education.

The speaker claims that all observation is subjective--colored by desire and expectation. 
While it would be tempting to concede that we all see things differently, careful scrutiny of the speaker's claim reveals that it confuses observation with interpretation. 
In fact, in the end the speaker's claim relies entirely on the further claim that there is no such thing as truth and that we cannot truly know anything. 
While this notion might appeal to certain existentialists and epistemologists, it runs against the grain of all scientific discovery and knowledge gained over the last 500 years.

It would be tempting to afford the speaker's daim greater merit than it deserves. After all, our everyday experience as humans informs us that we often disagree about what we observe around us. 
We've all uttered and heard uttered many times the phase "That's not the way I see it!" Indeed, everyday observations--for example, about whether a football player was out of bounds, or about which car involved in an accident ran the red light--vary depending not only on one's spatial perspective but also on one's expectations or desires. 
If I'm rooting for one football team, or if the player is well-known for his ability to make great plays while barely staying in bounds, my desires or expectations might influence what I think I observe. 
Or if I am driving one of the cars in the accident, or if one car is a souped-up sports car, then my desires or expectations will in all likelihood color my perception of the accident's events.

However, these sorts of subjective "observations" are actually subjective "interpretations'' of what we observe. 
Visitors to an art museum might disagree about the beauty of a particular work, or even about which color predominates in that work. 
In a court trial several jurors might view the same videotape evidence many times, yet some jurors might "observe" an incident of police brutality, will others "observe" the appropriate use of force to restrain a dangerous individual. 
Thus when it comes to making judgments about what we observe and about
remembering what we observe, each person's individual perspective, values, and even emotions help form these judgments and recollections. 
It is crucial to distinguish between interpretations such as these and observation, which is nothing more than a sensory experience. 
Given the same spatial perspective and sensory acuity and awareness, it seems to me that our observations would all be essentially in accord--that is, observation can be objective.

Lending credence to my position is Francis Bacon's scientific method, according to which we can know only that which we observe, and thus all truth must be based on empirical observation. 
This profoundly important principle serves to expose and strip away all subjective interpretation of observation, thereby revealing objective scientific truths. 
For example, up until Bacon's time the Earth was "observed" to lie at the center of the Universe, in accordance with the prevailing religious notion that man (humankind) was the center of God's creation. 
Applying Bacon's scientific method Galileo exposed the biased nature of this claim. Similarly, before Einstein time and space were assumed to be linear, in accordance with our "observation." 
Einstein's mathematical formulas suggested otherwise, and his theories have been proven empirically to be true. 
Thus it was our subjective interpretation of time and space that led to our misguided notions about them. 
Einstein, like history's other most influential scientists, simply refused to accept conventional interpretations of what we all observe.

In sum, the speaker confuses observation with interpretation and recollection.
It is how we make sense of what we observe, not observation itself, that is colored by our perspective, expectations, and desires. 
The gifted individuals who can set aside their subjectivity and delve deeper into empirical evidence, employing Bacon's scientific method, are the ones who reveal that observation not only can be objective but must be objective if we are to embrace the more fundamental notion that knowledge and truth exist.

This statement actually consists of a series of three related claims: (1) machines are tools of human minds; (2) human minds will always be superior to machines; and (3) it is because machines are human tools that human minds will always be superior to machines. 
While I concede the fn:st claim, whether I agree with the other two claims depends partly on how one defines "superiority," and partly on how willing one is to humble oneself to the unknown future scenarios.

The statement is clearly accurate insofar as machines are tools of human minds. After all, would any machine even exist unless a human being invented it? Of course not. 
Moreover, I would be hard-pressed to think of any machine that cannot be described as a tool. 
Even machines designed to entertain or amuse us--for example, toy robots, cars and video games, and novelty items--are in fact tools, which their inventors and promoters use for engaging in commerce and the business of entertainment and amusement. 
And, the claim that a machine can be an end in itself, without purpose or utilitarian function for humans whatsoever, is dubious at best, since I cannot conjure up even a single example of any such machine. 
Thus when we develop any sort of machine we always have some sort of end in mind a purpose for that machine.

As for the statement's second claim, in certain respects machines are superior. 
We have devised machines that perform number-crunching and other rote cerebral tasks with greater accuracy and speed than human minds ever could. 
In fact, it is because we can devise machines that are superior in these respects that we devise them--as our tools--to begin with.

However, if one defines superiority not in terms of competence in per-forming rote tasks but rather in other ways, human minds are superior. 
Machines have no capacity for independent thought, for making judgments based on normative considerations, or for developing emotional responses to intellectual problems.
Up until now, the notion of human-made machines that develop the ability to think on their own, and to develop so-called "emotional intelligence," has been pure fiction. 
Besides, even in fiction we humans ultimately prevail over such machines--as in the cases of Frankenstein's monster and Hal, the computer in 2001: A Space Odyssey. Yet it seems presumptuous to assert with confidence that humans will always maintain their superior status over their machines. 
Recent advances in biotechnology, particularly in the area of human genome research, suggest that within the 21st Century we'll witness machines that can learn to think on their own, to repair and nurture themselves, to experience visceral sensations, and so forth. 
In other words, machines will soon exhibit the traits to which we humans attribute our own superiority.

In sum, because we devise machines in order that they may serve us, it is fair to
characterize machines as "tools of human minds." 
And insofar as humans have the unique capacity for independent thought, subjective judgment, and emotional response, it also seems fair to claim superiority over our machines. 
Besides, should we ever become so clever a species as to devise machines that can truly think for themselves and look out for their own well-being, then query whether these machines of the future would be "machines'' anymore.










Whether effective leadership requires that a leader consistently follow his or her principles and objectives is a complex issue--one that is tied up in the problem of defining effective leadership in the first place. 
In addressing the issue it is helpful to consider, in turn, three distinct forms of leadership: business, political, and social-spiritual.

In the business realm, effective leadership is generally defined, at least in our corporate culture, as that which achieves the goal of profit maximization for a firm's shareholders or other owners. 
Many disagree, however, that profit is the appropriate measure of a business leader's effectiveness. 
Some detractors claim, for example, that a truly effective business leader must also fulfill additional duties--for example, to do no intentional harm to their customers or to the society in which they operate. 
Other detractors go further--to impose on business leaders an affirmative obligation to yield to popular will, by protecting consumers, preserving the natural environment, promoting education, and otherwise taking steps to help alleviate society's problems.

Whether our most effective business leaders are the ones who remain consistently committed to maximizing profits or the ones who appease the general populace by contributing to popular social causes depends, of course, on one's own definition of business success. 
In my observation, as business leaders become subject to closer scrutiny by the media and by social activists, business leaders will maximize profits in the long term only by taking reasonable steps to minimize the social and environmental harm their businesses cause. 
Thus the two definitions merge, and the statement at issue is ultimately correct.

In the political realm the issue is no less complex. 
Definitions of effective political leadership are tied up in the means a leader uses to wield his or her power and to obtain that power in the first place. 
Consider history's most infamous tyrants and despots--such as Genghis Khaan, Stalin, Mao, and Hider. 
No historian would disagree that these individuals were remarkably effective leaders, and that each one remained consistently committed to his tyrannical objectives and Machiavellian principles. 
Ironically, it was stubborn commitment to objectives that ultimately defeated all except Khan. Thus in the short term stubborn adherence to one's objectives might serve a political leader's interest in preserving his or her power; yet in the long term such behavior invariably results in that leader's downfall if the principles are not in accord with those of the leader's would-be followers.

Finally, consider social-spiritual leadership. 
Few would disagree that through their ability to inspire others and lift the human spirit Mahatma Gandhi and Martin Luther King were eminently effective in leading others to effect social change through civil disobedience. 
It seems to me that this brand of leadership, in order to be effective, inherently requires that the leader remain steadfastly committed to principle. 
Why? It is commitment to principle that is the basis for this brand of leadership in the first place. 
For example, had Gandhi advocated civil disobedience yet been persuaded by dose advisors that an occasional violent protest might be effective in gaining India's independence from Britain, no doubt the result would have been immediate forfeiture of that leadership. 
In short, social-spiritual leaders must not be hypocrites; otherwise, they will lose all credibility and effectiveness.

In sum, strict adherence to principles and objectives is a prerequisite for effective social-spiritual leadership--both in the short and long term. 
In contrast, political leadership wanes in the long term unless the leader ultimately yields to the will of the followers.

Finally, when it comes to business, leaders must strike a balance between the objective of profit maximization--the traditional measure of effectiveness--and yielding to certain broader obligations that society is now imposing on them.






In general, I agree with the assertion that intense media scrutiny nearly always serves to diminish the reputation of society's would-be heroes, for the chief reason that it seems to be the nature of media to look for ways to demean public figures whether heroic or not. 
Moreover, while in isolated cases our so-called heroes have vindicated themselves and restored their reputations diminished by the media, in my observation these are exceptional cases to the general rule that once slandered, the reputation of any public figure, hero or otherwise, is forever tarnished.

The chief reason why I generally agree with the statement has to do with the forces that motivate the media in the first place. 
The media generally consist of profit-seeking entities, whose chief objective is to maximize profits for their shareholders or other owners. 
Moreover, our corporate culture has sanctioned this objective by codifying it as a fiduciary obligation of any corporate executive.
For better or worse, in our society media viewers, readers, and listeners find information about the misfortunes and misdeeds of others, especially heroic public figures, far more compelling than information about their virtues and accomplishments.
In short, we love a good scandal. One need look no further than the newsstand, local television news broadcast, or talk show to find ample evidence that this is the case. 
Thus in order to maximize profits the media are simply giving the public what they demand scrutiny of heroic public figures that serves to diminish their reputation.

A second reason why I fundamentally agree with the statement is that, again for better or worse, intense media scrutiny raises a presumption, at least in the public's collective mind, that their hero is guilty of some sort of character flaw or misdeed. This presumption is understandable. 
After all, I think any demographic study would show that the vast majority of people relying on mainstream media for their information lack the sort of critical-thinking skills and objectivity to see beyond what the media feeds them, and to render a fair and fully informed judgment about a public figure--heroic or otherwise.

A third reason for my agreement with the statement has to do with the longer-term fallout from intense media scrutiny and the presumption discussed above. 
Once tarnished as a result of intense media scrutiny, a person's reputation is forever besmirched, regardless of the merits or motives of the scrutinizers. 
Those who disagree with this seemingly cynical viewpoint might cite cases in which public figures whose reputations had been tarnished were ultimately vindicated. For example, certain celebrities have successfully challenged rag sheets such as
the National Enquirer in the courts, winning large damage awards for libel.
Yet in my observation these are exceptional cases; besides, a damage award is no indication that the public has expunged from its collective memory a perception that the fallen hero is guilty of the alleged character flaw or peccadillo.

In sum, the statement is fundamentally correct. 
As long as the media are motivated by profit, and as long as the public at large demands stories that serve to discredit, diminish, and destroy reputations, the media will continue to harm whichever unfortunate individuals become their cynosures. 
And the opportunity for vindication is little consolation in a society that seems to thrive, and even feed, on watching heroes being knocked off their pedestals.







The speaker asserts that imagination is "sometimes" more valuable than experience
because individuals who lack experience can more freely imagine possibilities for approaching tasks than those entrenched in established habits and attitudes.
I fundamentally agree; however, as the speaker implies, it is important not to overstate the comparative value of imagination. 
Examples from the arts and the sciences aptly illustrate both the speaker's point and my caveat.

One need only observe young children as they go about their daily lives to appreciate the role that pure imagination can play as an aid to accomplishing tasks. Young children, by virtue of their lack of experience, can provide insights and valuable approaches to adult problems.
The speaker's contention also finds ample empirical support in certain forms of artistic accomplishment and scientific invention. History is replete with evidence that our most gifted musical composers are young, relatively inexperienced, individuals. 
Notables ranging from Mozart to McCartney come immediately to mind. 
Similarly, the wide-eyed wonder of inexperience seems to spur scientific innovation. 
Consider the science fiction writer Jules Veme, who through pure imagination devised highly specific methods and means for transporting humans to outer space. What makes his imaginings so remarkable is that the actual methods and means for space flight, which engineers settled on through the experience of extensive research and trial-and-error, turned out to be essentially the same ones Verne had imagined nearly a century earlier!
Of course, there are many notable exceptions to the rule that imagination unfettered by experience breeds remarkable insights and accomplishments. 
Duke EUington, perhaps jazz music's most prolific composers, continued to create new compositions until late in life.

Thomas Edition, who registered far more patents with the U.S. patent office than any other person, continued to invent until a very old age. 
Yet, these are exceptions to the general pattern. 
Moreover, the later accomplishments of individuals such as these tend to build on earlier ones, and therefore are not as truly inspired as the earlier ones, which sprung from imagination less fettered by life experience.
On the other hand, it is important not to take this assertion about artistic and scientific accomplishment too far. 
Students of the arts, for instance, must learn theories and techniques, which they then apply to their craft whether music performance, dance, or acting. And, creative writing requires the cognitive ability to understand how language is used and how to communicate ideas. 
Besides, creative ability is itself partly a function of intellect; that is, creative expression is a marriage of one's cognitive abilities and the expression of one's feelings and emotions. 
In literature, for example, a rich life experience from which to draw ideas is just as crucial to great achievement as imagination.
 For example, many critics laud Mark Twam's autobiography, which he wrote on his death bed, as his most inspired work. 
And, while the direction and goals of scientific research rely on the imaginations of key individuals, most scientific discoveries and inventions come about not by sudden epiphanies of youthful star-gazers but rather by years and years of trial-and-error in corporate research laboratories.

In sum, imagination can serve as an important catalyst for artistic creativity and scientific invention. 
Yet, experience can also play a key role; in fact, in literature and in science it can play just as key a role as the sort of imagination that inexperience breeds.










I agree with the statement insofar as our leading voices tend to come from people whose ideas depart from the status quo.
 However, I do not agree that what motivates these iconoclasts is a mere desire to be different; in my view they are driven primarily by their personal convictions. Supporting examples abound in all areas of human endeavor—including politics, the arts, and the physical sciences.
When it comes to political power, I would admit that a deep-seated psychological need to be noticed or to be different sometimes lies at the heart of a person's drive to political power and fame. 
For instance, some astute presidential historians have described Clinton as a man motivated more by a desire to be great than to accomplish great things. 
And many psychologists attribute Napoleon's and Mussolini's insatiable lust for power to a so-called "short-man complex"--a need to be noticed and admired in spite of one's small physical stature.

Nevertheless, for every leading political voice driven to new ideas by a desire to be noticed or to be different, one can cite many other political leaders clearly driven instead by the courage of their convictions. 
Iconoclasts Mahatma Gandhi and Martin Luther King, for example, secured prominent places in history by challenging the status quo through civil disobedience. 
Yet no reasonable person could doubt that it was the conviction of their ideas that drove these two leaders to their respective places.

Turning to the arts, mavericks such as Dali, Picasso and Warhol, who departed from
established rules of composition, ultimately emerge as the leading artists. 
And our most influential popular musicians are the ones who are flagrantly "different." 
Consider, for example, jazz pioneers Thelonius Monk and Miles Davis, who broke all the harmonic rules, or folk musician-poet Bob Dylan, who established a new standard for lyricism. 
Were all these leading voices driven simply by a desire to be different? Perhaps; but my intuition is that creative urges are born not of ego but rather of some intensely personal commitment to an aesthetic ideal.
As for the physical sciences, innovation and progress can only result from challenging conventional theories--that is, the status quo. 
Newton and Einstein, for example, both refused to blindly accept what were perceived at their time as certain rules of physics. 
As a result, both men redefined those rules. 
Yet it would be patently absurd to assert that these two scientists were driven by a mere desire to conjure up "different" theories than those of their contemporaries or predecessors. 
Surely it was a conviction that their theories were better that drove these geniuses to their places in history.

To sum up, when one examines history's leading voices it does appear that they typically bring to the world something radically different than the status quo. 
Yet in most cases this sort of iconoclasm is a byproduct of personal conviction, not iconoclasm for its own sake.








Is complete honesty a useful virtue in politics? 
The speaker contends that it is not, for the reason that political leaders must sometimes lie to be effective. 
In order to evaluate this contention it is necessary to examine the nature of politics, and to distinguish between short-term and long-term effectiveness.

On the one hand are three compelling arguments that a political leader must sometimes be less than truthful in order to be effective in that leadership. 
The first argument lies in the fact that politics is a game played among politicians--and that to succeed in the game one must use the tools that are part-and-parcel of it. 
Complete forthrightness is a sign of vulnerability and naivete, neither of which will earn a politician respect among his or her opponents, and which those opponents will use to every advantage against the honest politician.

Secondly, it is crucial to distinguish between misrepresentations of fact in other words, lies--and mere political rhetoric. 
The rhetoric of a successful politician eschews rigorous factual inquiry and indisputable fact while appealing to emotions, ideals, and subjective interpretation and characterizations. 
Consider, for example, a hypothetical candidate for political office who attacks the incumbent opponent by pointing out only certain portions of that opponent's legislative voting record. 
The candidate might use a vote against a bill eliminating certain incentives for local businesses as "dear evidence" that the opponent is "anti-business," "bad for the economy," or "out of touch with what voters want." 
None of these allegations are outright lies; they are simply the rhetorical cant of the effective politician.

Thirdly, politics is a business born not only of idealism but also of pragmatism; after all, in order to be effective a politician must gain and hold onto political power, which means winning elections.
In my observation some degree of pandering to the electorate and to those who might lend financial support in reelection efforts is necessary to maintain that position. 
Modern politics is replete with candidates who refused to pander, thereby mining their own chance to exercise effective leadership.

Although in the short term being less-than-truthful with the public might serve a political leader's interest in preserving power, would-be political leaders who lack requisite integrity ultimately forfeit their leadership. 
Consider Richard Nixon, whose leadership seemed born not of ideology but of personal ambition, which bred contempt of the very people who sanctioned his leadership in the first place; the ultimate result was his forfeiture of that leadership. In contrast, Ronald Reagan was a highly effective leader largely because he honestly, and deeply, believed in the core principles that he espoused and advocated during his presidency--and his constituency sensed that genuineness and responded favorably to it. 
Moreover, certain types of sociopolitical leadership inherently require the utmost integrity and honesty. 
Consider notable figures such as Gandhi and King, both of whom were eminently effective in leading others to practice the high ethical and moral standards which they themselves advocated. 
The reason for this is simple: A high standard for one's own personal integrity is a prerequisite for effective moral leadership.

To sum up, I concede that the game of politics calls for a certain measure of posturing and disingenuousness. 
Yet, at the end of the game, without a countervailing measure of integrity, political game-playing will serve to diminish a political leader's effectiveness perhaps to the point where the politician forfeits the game.






Are products of human nature such as war and crime actually products of the human condition--specifically, lack of resources and territory? 
The speaker daims so.
 I strongly disagree, however. 
Whether we look at science and history, or simply look around us in our daily lives, we see ample evidence that human aggression is the product of our nature as humans--and not of our circumstances.

First of all, the claim runs contrary to my personal observation about individual behavior--especially when it comes to males. 
One need look no further than the local school-ground or kindergarten playroom to see the roots of crime and war. 
Every school-yard has its bully who delights in tormenting meeker school mates; and in every kindergarten classroom there is at least one miscreant whose habit is to snatch away the favorite toys of classmates--purely for the enjoyment of having seized property from another. 
And these behaviors are clearly not for want of resources or territory. 
Thus the only reasonable explanation is that they are products of human nature--not of the human condition.   

Secondly, the daim flies in face of what scientists have learned about genetically determined human traits. 
Many human traits--not just physical ones but psychological ones as well are predetermined at birth. 
And to a great extent we have inherited our genetic predisposition from our non-human ancestors. 
One might argue that lower animal species engage in warlike behavior for the main reason that they must do so to protect their territory, their dan, or for food
not because of their nature. 
Yet, this point begs the question; for we humans have been genetically programmed, through the evolutionary process, to behave in similar ways. 
In other words, doing so is simply our nature.

Thirdly, the claim makes little sense in the context of human history. 
Prior to the last few centuries the inhabitable regions of our planet provided ample territory and resources--such as food and cultivable land--to accommodate every human inhabitant. 
Yet our distant ancestors engaged in war and crime anyway. What else explains this, except that it is part of our inherent nature to engage in aggressive behavior toward other humans? 
Moreover, if we consider the various experiments with Marx's Communism, it becomes clear that the pure Marxist State in which all territory and resources are shared according to the needs of each individual does not work in practice.
 Every attempt, whether on the macro- or micro-level, has failed at the hands of a few demagogues or despots, who aggress and oppress like playground bullies.

In sum, the author of this statement misunderstands the roots of such phenomena as war and crime. 
The statement runs contrary to my personal observations of human behavior, to the scientific notions of genetic predisposition and evolution of species, and to the overwhelming lack of evidence that providing ample resources to people solves these problems.







The speaker's assertion that work in any field can be judged only by experts in that field amounts to an unfair generalization, in my view. 
I would concur with the speaker when it comes to judging the work of social scientists, although I would strongly disagree when it comes to work in the pure physical sciences, as explained in the following discussion.

With respect to the social sciences, the social world presents a seamless web of not only anthropogenic but also physical forces, which interact in ways that can be understood only in the context of a variety of disciplines. 
Thus experts from various fields must collectively determine the merit of work in the social sciences. 
For example, consider the field of cultural anthropology. 
The merits of researcher's findings and conclusions about an ancient civilization must be scrutinized by biochemists, geologists, linguists, and even astronomers.

Specifically, by analyzing the hair, nails, blood and bones of mummified bodies, biochemists and forensic scientists can pass judgment on the anthropologist's conjectures about the life expectancy, general well-being, and common causes of death of the population. 
Geologists are needed to identify the source and age of the materials used for tools, weapons, and structures--thereby determining whether the anthropologist extrapolated correctly about the civilization's economy, trades and work habits, life styles, extent of travel and mobility, and so forth. 
Linguists are needed to interpret hieroglyphics and extrapolate from found fragments of writings. 
And astronomers are sometimes needed to determine with the anthropologist's explanations for the layout of an ancient city or the design, structure and position of monuments, tombs, and temples is convincing-because ancients often looked to the stars for guidance in building cities and structures.

In contrast, the work of researchers in the purely physical sciences can be judged only by their peers. 
The reason for this is that scientific theories and observations are either meritorious or not, depending solely on whether they can be proved or disproved by way of the scientific method. 
For example, consider the complex equations which physicists rely upon to draw conclusions about the nature of matter, time, and space, or the origins and future of the universe. 
Only other physicists in these specialties can understand, let alone judge, this type of theoretical work. 
Similarly, empirical observations in astrophysics and molecular physics require extremely sophisticated equipment and processes, which only experts in these fields have access to and who know how to use reliably.
Those who disagree that only inside experts can judge scientific work might point out that the expertise of economists and pubic-policy makers is required to determine whether the work is worthwhile from a more mundane economic or political viewpoint. 
Detractors might also point out that ultimately it is our philosophers who are best equipped to judge the ultimate import of ostensibly profound scientific discoveries. Yet these detractors miss the point of what I take to be the speaker's more narrow claim: that the integrity and quality of work---disregarding its socioeconomic utility----can be judged only by experts in the work's field.

In sum, in the social sciences no area of inquiry operates in a vacuum. 
Because fields such as anthropology, sociology, and history are so closely intertwined and even dependent on the physical sciences, experts from various fields must collectively determine the integrity and quality of work in these fields. However, in the purely physical sciences the quality and integrity of work can be adequately judged only by inside experts, who are the only ones equipped with sufficient technical knowledge to pass judgment.







Should politics and morality be treated as though they are mutually exclusive? I strongly agree with the speaker that any person claiming so fails to understand either the one or the other. 
An overly narrow definition of morality might require complete forthrightness and candidness in dealings with others.
 However, the morality of public politics embraces far broader concerns involving the welfare of society, and recognizes compromise as a necessary, and legitimate, means of addressing those concerns.

It is wrong-headed to equate moral behavior in politics with the simple notions of honesty and putting the other fellow's needs ahead of one's own----or other ways which we typically measure the morality of an individual's private behavior. 
Public politics is a game played among professional politicians--and to succeed in the game one must use the tools that are part-and-parcel of it. 
Complete forthrightness is a sign of vulnerability and naivet~, neither of which will earn a politician respect among his or her opponents, and which opponents will use to every advantage against the honest politician. 
Moreover, the rhetoric of a successful politician eschews rigorous factually inquiry and indisputable fact while appealing to emotions, ideals, and subjective interpretation and characterizations. 
For example, the politician who claims his opponent is "anti-business," "bad for the economy," or "out of touch with what voters want" is not necessarily behaving immorally. 
We must understand that this sort of rhetoric is part-and-parcel of public politics, and thus kept in perspective does not harm the society—as long as it does not escalate to outright lying.

Those who disagree with the statement also fail to understand that in order to gain the opportunity for moral leadership politicians must engage in certain compromises along the way.
 Politics is a business born not only of idealism but also of pragmatism insofar as in order to be effective a politician must gain and hold onto political power. 
In my observation, some degree of pandering to the electorate and to those who might lend financial support for reelection efforts is necessary to maintain that position. 
Modern politics is replete with candidates who refused to pander, thereby mining their own chance to exercise effective leadership.

Finally, those who claim that effective politicians need not concern themselves with morality fail to appreciate that successful political leadership, ifit is to endure, ultimately requires a certain measure of public morality--that is, serving the society with its best interests as the leader's overriding concern. 
Consider the many leaders, such as Stalin and Hitler, whom most people would agree were egregious violators of public morality. 
Ultimately such leaders forfeit their leadership as a result of the immoral means by which they obtain or wield their power. Or consider less egregious examples such as President Nixon, whose contempt for the very legal system that afforded him his leadership led to his forfeiture of that leadership. 
It seems to me that in the short term amoral or immoral public behavior might serve a political leader's interest in preserving power; yet in the long term such behavior invariably results in that leader's downfall.

In sum, I fundamentally agree with the statement. It recognizes that the "game" of politics calls for a certain amount of disingenuousness that we might associate with dubious private morality. 
And it recognizes that such behavior is a necessary means to the final objective of moral political leadership. 
Besides, at the end of the political game any politician failing to exercise moral leadership ultimately forfeits the game.






The speaker claims that great advances in knowledge necessarily involve rejection of authority. 
To the extent that political authority impedes such advances, I agree with this claim. Otherwise, in my view most advances in knowledge actually embrace certain forms of authority, rather than rejecting authority out of hand.
One striking example of how political authority can impede the advancement of knowledge involves what we know about the age and evolution of planet Earth. 
In earlier centuries the official Church of England called for a literal interpretation of the Bible, according to which the Earth's age is determined to be about 6,000 years. 
IfWestern thinkers had continued to yield to the ostensible authority of the Church, the fields of structural and historical geology would never have advanced beyond the blind acceptance of this contention as fact.

A more modern example of how yielding to political authority can impede the advancement of knowledge involves the Soviet Refusenik movement of the 1920s. During this time period the Soviet government attempted not only to control the direction and the goals of its scientists' research but also to distort the outcome of that research. 
During the 1920s the Soviet government quashed certain areas of scientific inquiry, destroyed entire research facilities and libraries, and caused the sudden disappearance of many scientists who were engaged in research that the state viewed as a potential threat to its power and authority.
 Not surprisingly, during this time period no significant advances in scientific knowledge occurred under the auspices of the Soviet government.

However, given a political climate that facilitates free thought and honest intellectual inquiry, great advances in knowledge can be made by actually embracing certain forms of "authority."

A good example involves modern computer technology. Only by building on, or embracing, certain well-established laws of physics were engineers able to develop silicon-based semi-conductor technology. 
Although new biotechnology research suggests that organic, biochemical processors will replace artificial semi-conductors as the computers of the future, it would be inappropriate to characterize this leap in knowledge as a rejection of authority.

In sum, to the extent that political authority imposes artificial constraints on knowledge, I agree that advances in knowledge might require rejection of authority. 
Otherwise, in my observation advances in knowledge more typically embrace and build on authoritative scientific principles and laws, and do not require the rejection of any type of authority.







The speaker claims that great advances in knowledge necessarily involve rejection of authority.
 To the extent that political authority impedes such advances, I agree with this claim. 
Otherwise, in my view most advances in knowledge actually embrace certain forms of authority, rather than rejecting authority out of hand.
One striking example of how political authority can impede the advancement of knowledge involves what we know about the age and evolution of planet Earth. 
In earlier centuries the official Church of England called for a literal interpretation of the Bible, according to which the Earth's age is determined to be about 6,000 years. 
If Western thinkers had continued to yield to the ostensible authority of the Church, the fields of structural and historical geology would never have advanced beyond the blind acceptance of this contention as fact.

A more modern example of how yielding to political authority can impede the advancement of knowledge involves the Soviet Refusenik movement of the 1920s. During this time period the Soviet government attempted not only to control the direction and the goals of its scientists' research but also to distort the outcome of that research. 
During the 1920s the Soviet government quashed certain areas of scientific inquiry, destroyed entire research facilities and libraries, and caused the sudden disappearance of many scientists who were engaged in research that the state viewed as a potential threat to its power and authority. 
Not surprisingly,
during this time period no significant advances in scientific knowledge occurred under the auspices of the Soviet government.

However, given a political climate that facilitates free thought and honest intellectual inquiry, great advances in knowledge can be made by actually embracing certain forms of "authority."

A good example involves modern computer technology. Only by building on, or embracing, certain well-established laws of physics were engineers able to develop silicon-based semi-conductor technology. 
Although new biotechnology research suggests that organic, biochemical processors will replace artificial semi-conductors as the computers of the future, it would be inappropriate to characterize this leap in knowledge as a rejection of authority. 

In sum, to the extent that political authority imposes artificial constraints on knowledge, I agree that advances in knowledge might require rejection of authority.
 Otherwise, in my observation advances in knowledge more typically embrace and build on authoritative scientific principles and laws, and do not require the rejection of any type of authority.







Does a nation's greatness lie in the general welfare of its people rather than in the
achievements of its artists, rulers, and scientists, as the speaker claims? 
I find this claim problematic in two respects. First, it fails to define "general welfare." 
Second, it assumes that the sorts of achievements that the speaker cites have little to do with a nation's general welfare--when in fact they have everything to do with it.

At first blush the speaker's claim might appear to have considerable merit. After all, the overriding imperative for any democratic state is to enhance the general welfare of its citizenry. 
Yet the speaker fails to provide a clear litmus test for measuring that welfare. 
When we speak of "promoting the general welfare," the following aims come to mind: public health and safety, security against military invasions, individual autonomy and freedom, cultural richness, and overall comfort--that is, a high standard of living. 
Curiously, it is our scientists, artists, and political leaders-----or so-called "rulers" who by way of their achievements bring these aims into fruition. 
Thus, in order to determine what makes a nation great it is necessary to examine the different sorts of individual achievements that ostensibly promote these aims.

Few would disagree that many scientific achievements serve to enhance a nation's general welfare. 
Advances in the health sciences have enhanced our physical well-being, comfort, and life span. 
Advances in technology have enabled us to travel to more places, communicate with more people from different walks of life, and learn about the world from our desktops.

Advances in physics and engineering make our abodes and other buildings safer, and enable us to travel to more places, and to travel to more distant places, with greater safety and speed. 
Artistic achievement is also needed to make a nation a better place for humans overall. 
Art provides inspiration, lifts the human spirit, and incites our creativity and imagination, all of which spur us on to greater accomplishments and help us appreciate our own humanity. 
Yet the achievements of scientists and artists, while integral, do not suffice to ensure the welfare of a nation's citizens.
 In order to survive, let alone be great, a nation must be able to defend its borders and to live peaceably with other nations. 
Thus the military and diplomatic accomplishments of a nation's leaders provide an integral contribution to the general welfare of any nation's populace.

Notwithstanding the evidence that, in the aggregate, individual achievements of the sorts listed above are what promote a nation's general welfare, we should be careful not to hastily assume that a nation is necessarily great merely by virtue of the achievements of individual citizens. 
Once having secured the safety and security of its citizens, political rulers must not exploit or oppress those citizens. 
Also, the populace must embrace and learn to appreciate artistic accomplishment, and to use rather than misuse or abuse scientific knowledge. 
Of particular concern are the many ways in which scientific achievements have served to diminish our quality of life, thereby impeding the general welfare. 
It is through scientific "achievements" that chemicals in our food, water, and air increase the incidence and variety of cancers; that our very existence as a species is jeopardized by the threat of nuclear warfare; and that greenhouse gases which deplete our ozone layer and heat the Earth's atmosphere threaten civilization itself.

In sum, in asserting that general welfare--and neither the scientific, artistic, nor political achievements of individuals--provides the yardstick for measuring a nation's greatness, the speaker misses the point that general welfare is the end product of individual achievements. 
Besides, achievements of artists, scientists, and political leaders rarely inure only to one particular nation. 
Rather, these achievements benefit people the world over.
Accordingly, by way of these achievements the world, not just one nation, grows in its greatness.






I strongly agree with the speaker's threshold claim that international relations can never be completely harmonious. 
To assert otherwise would be Pollyannaish and would fly in the face of human history--which is largely a story of power struggles, war, and general discord between nations and cultures. 
However, the speaker's rationale, although appealing and not without merit, is inadequate to explain why total accord among all nations is impossible.

Supporting the speaker's claim is the fact that each culture has its own distinct ethos-- consisting of its core values, principles, and spirit which defines and distinguishes the culture. 
And I agree that the failure of one culture to understand the unique ethos of another is what often lies at the root of discord between nations and cultures. 
An apt current-day illustration of this point involves a certain American Indian tribe in Washington State, and its traditional custom of whale hunting.
 Environmentalists denounce the practice as unnecessary endangerment of a species.
 However, underlying this custom is a centuries-old spiritual belief that ceremonial whale-hunting is sacrificial ritual honoring Nature, and an even more fundamental Native American ethos, characterized by a far greater respect for animals and for Nature than the ethos of white Americans.

The sort of unfair judgment exemplified by certain white Americans' denunciation of Native American customs and practices is what sociologists term "ethnocentricity"-- reference to one's own cultural ethos as a standard for judging the values and actions of other people. 
History informs us all too well that ethnocentricity leads inexorably to disharmony. Virtually all wars are rooted in religious ethnocentricity.
 Political ethnocentricity results in imperialism--assimilation of any and all peoples with complete disregard or respect for ethos.
Understandable resistance to British imperialism during the 19th Century resulted in the oppression and demise of many indigenous peoples of Africa and Indonesia. And ethnocentricity on a societal level can lead to mass persecution, as demonstrated by the legions of citizens and soldiers brainwashed by the Nazis into believing that the Jewish race posed some sort of threat to German society and to the Arian race.

Thus the speaker's contention that harmonious international relations are impossible because of conflicting cultural values finds ample support from history. Yet, as compelling as this argument might be, it nevertheless suffers from two notable deficiencies. 
First, in spite of their differences the world's mainstream cultures all share certain fundamental tenets--particularly about the dignity of human life and that they all agree upon these tenets, at least tacitly. 
And people should judge other cultures against such universal standards. Otherwise, the end result is that we find ourselves acquiescing in or even sanctioning war and other such atrocities. 
Since all cultures share a universal ethos the speaker's rationale seems inadequate. Discord occurs not only as a result of an ethos clash but also upon violation of the universal ethos.

A second problem with the speaker's rationale is that it overlooks the fact that we can find considerable discord within almost every culture. 
On a microcosmic scale we all observe so-caUed infighting among members of the same church congregations, political factions, and so forth. 
On a larger scale infighting is all too evident--from overt gang warfare and civil war to covert corporate espionage and political back-stabbing. 
Thus even if all cultures were to share the same ethos the promise of complete harmony would still be an illusory one. In short, contentiousness seems to be part of human nature.

To sum up, I agree with the speaker that complete harmony among nations is unrealistic, but not just because of conflicting cultural values; it runs contrary to human nature. 
Yet, the outlook for international relations is not necessarily so grim.
 An enlightened understanding of the ethos of other cultures, and of our own cultural bias, can foster a universal ethos of respect for human dignity and life. 
The end result would be to stem, or at least minimize, discord among nations and cultures.






Are people who make the greatest contributions to society those who pursue their personal intellectual interests, as the speaker asserts?
 Or are they the ones who focus instead on areas that are most likely to benefit society?
I strongly agree with the speaker, for three reasons.

First of all, by human nature we are motivated to pursue activities in which we excel. 
To compel people to focus their intellectual interests only on certain areas would be to force many to waste their true talents. 
For example, imagine relegating today's preeminent astrophysicist Stephen Hawking to researching the effectiveness of affirmative-action legislation in reducing workplace discrimination. 
Admittedly, this example borders on hyperbole. Yet the aggregate effect of realistic cases would be to waste the intellectual talents of our world's scholars and
researchers.

Secondly, it is unusual avenues of personal interest that most often lead to the greatest contributions to society.
 Intellectual and scientific inquiry that breaks no new ground amount to wasted time, talent, and other resources. 
History is laden with quirky claims of scholars and researchers that turned out stunningly significant--that the sun lies at the center of our universe, that time and space are relative concepts, that matter consists of discrete particles, that humans evolved from other life forms, to name a few. 
One current area of unusual research is terraforrning---creating biological life and a habitable atmosphere where none existed before. 
This unusual research area does not immediately address society's pressing social problems. 
Yet in the longer term it might be necessary to colonize other planets in order to ensure the survival of the human race; and after all, what could be a more significant contribution to society than preventing its extinction?
Thirdly, to adopt a view that runs contrary to the speaker's position would be to sanction certain intellectual pursuits while proscribing others which smacks of thought control and political oppression.
 It is dangerous to afford ultimate decision-making power about what intellectual pursuits are worthwhile to a handful of regulators, legislators, or elitists, since they bring to bear their own quirky notions about what is worthwhile, and since they are notoriously susceptible to influence-peddling which renders them untrustworthy in any event. 
Besides, history informs us well of the danger inherent in setting official research priorities. A telling modern example involves the Soviet government's attempts during the 1920s to not only control the direction and the goals of its scientists' research but also to distort the outcome of that research----ostensibly for the greatest good of the greatest number of people. 
During the 1920s the Soviet government quashed certain areas of scientific inquiry, destroyed entire research facilities and libraries, and caused the sudden disappearance of many scientists who were viewed as threats to the state's authority. 
Not surprisingly, during this time period no
significant scientific advances occurred under the auspices of the Soviet government.

Those who would oppose the speaker's assertion might argue that intellectual inquiry in certain areas, particularly the arts and humanities, amounts to little more than a personal quest for happiness or pleasure, and therefore is of little benefit to anyone but the inquirer. 
This specious argument overlooks the palpable benefits of cultivating the arts. 
It also ignores the fact that earnest study in the humanities affords us wisdom to know what is best for society, and helps us understand and approach societal problems more critically, creatively, and effectively. 
Thus, despite the lack of a tangible nexus between certain areas of intellectual inquiry and societal benefit, the nexus is there nonetheless.

In sum, I agree that society is best served when people are allowed unfettered freedom of intellectual inquiry and research, and use that freedom to pursue their own personal interests. 
Engaging one's individual talents in one's particular area of fascination is most likely to yield advances, discoveries, and a heightened aesthetic appreciation that serve to make the world a better and more interesting place in which to live.






Does "originality" mean putting together old ideas in new ways, as the speaker contends, rather than conjuring up truly new ideas?
 Although I agree that in various realms of human endeavor, such as linguistics, law, and even the arts, so-called "new" or "original" ideas rarely are.
 However, when it comes to the physical sciences originality more often entails chartering completely new intellectual territory.

The notion that so-called "originality" is actually variation or synthesis of existing ideas finds its greatest support in linguistics and in law. 
Regarding the former, in spite of the many words in the modern English language that are unique to Western culture, modern English is derived from, and builds upon, a variety of linguistic traditions--and ultimately from the ancient Greek and Latin languages.
 Were we to insist on rejecting tradition in favor of purely modern language we would have essentially nothing to say. The same holds true for all other modern
languages. 
As for law, consider the legal system in the United States, which is deeply rooted in traditional English common-law principles of equity and justice. 
The system in the U.S. requires that new, so-called "modern" laws be consistent with and indeed build upon—those traditional principles.

Even in the arts--where one might think that true originality must surely reside--so-called "new" ideas almost always embrace, apply, or synthesize what came earlier. For example, most "modern" visual designs, forms, and elements are based on certain well-established aesthetic ideals--such as symmetry, balance, and harmony. Admittedly, modern art works often eschew these principles in favor of true originality. 
Yet, in my view the appeal of such works lies primarily in their novelty and brashness. 
Once the ephemeral novelty or shock dissipates, these works quickly lose their appeal because they violate fn:rnly established artistic ideals. 
An even better example from the arts is modern rock-and-roll music, which upon first listening might seem to bear no resemblance to dassical music traditions. 
Yet, both genres rely on the same 12-note scale, the same notions of what harmonies are pleasing to the ear, the same forms, the same rhythmic meters, and even many of the same melodies.

When it comes to the natural sciences, however, some new ideas are truly original while others put established ideas together in new ways. 
One striking example of truly original scientific advances involves what we know about the age and evolution of the Earth. 
In e~rlier centuries the official Church of England called for a literal interpretation of the Bible, according to which the Earth's age is determined to be about 6,000 years.
 If Western thinkers had simply put these established ideas together in new ways the fields of structural and historical geology might never have advanced further. A more recent example involves Einstein's theory of relativity. 
Einstein theorized, and scientists have since proven empirically, that the pace of time and possibly the direction of time as well, is relative to the observer's motion through space. 
This truth ran so contrary to our subjective, linear experience, and to previous notions about time and space, that I think Einstein's theory can properly be characterized as truly original.

However, in other instances great advances in science are made by putting together current theories or other ideas in new ways. 
For example, only by building on certain well-established laws of physics were engineers able to develop silicon-based semiconductor technology. 
And, only by struggling to reconcile the quantum and relativity theories have physicists now posited a new so-called "string" theory, which puts together the two preexisting theories in a completely new way.

To sum up, for the most part originality does not reject existing ideas but rather embraces, or synthesizes what came before. 
In fact, in our modern languages, our new laws, and even our new art, existing ideas are reflected, not shunned. 
But, when it comes to science, whether the speaker's claim is true must be determined on a case-by-case basis, with each new theory or innovation.







Some measure of consistency and stability in the law is critical for any society to function. 
Otherwise, I strongly agree with the speaker's assertion that laws should be flexible enough to adapt to different circumstances, times and places. 
The law of marital property apdy illustrates this point.

On the one hand, a certain measure of consistency, stability, and predictability in our laws is required in order for us to understand our legal obligations and rights as we go about our day-to-day business as a society. 
For example, in order for private industry to thrive, businesses must be afforded the security of knowing their legal rights and obligations visi-vis employees, federal regulatory agencies, and tax authorities--as well as their contractual rights and duties vis-~t-vis customers and suppliers.  
Undue uncertainty in any one of these areas would surely have a chilling effect on business. 
Moreover, some measure of consistency in the legal environment from place to place promotes business expansion as well as interstate and international commerce, all of which are worthwhile endeavors in an increasingly mobile society.

On the other hand, rigid laws can result in unfairness if applied inflexibly in all places at all times. 
The framers of the U.S. Constitution recognized the need both for a flexible legal system and for flexible laws--by affording each state legal jurisdiction over all but interstate matters. 
The framers understood that social and economic problems, as well as standards of equity and fairness, can legitimately change over time and vary from region to region----even from town to town. 
And our nation's founders would be pleased to see their flexible system that promotes equity and fairness as it operates today.

Consider, for example, marital property rights, which vary considerably from state to state,  and which have evolved considerably over time as inflexible, and unfair, systems have given way to more flexible, fairer ones. 
In earlier times husbands owned all property acquired during marriage as well as property brought into the marriage by either spouse.
 Understandably, this rigid and unfair system ultimately gave way to separate-property systems, which acknowledged property rights of both spouses. 
More recently certain progressive states have adopted even more flexible, and fairer, "community property" systems, under which each spouse owns half of all property acquired during the marriage, while each spouse retains a separate-property interest in his or her other property. 
Yet even these more egalitarian community-property systems can operate unfairly whenever spouses contribute unequally; accordingly, some community-property states are now modifying their systems for even greater flexibility and fairness.

Thus, the evolution of state marital-property laws aptly illustrates the virtue of a legal system that allows laws to evolve to keep pace with changing mores, attitudes, and our collective sense of equity. 
This same example also underscores the point that inflexible laws tend to operate unfairly, and properly give way to more flexible ones--as our nation's founders intended.






The speaker claims that individual enterprise, energy, and commitment, and not team-work, provide the impetus for innovation in every case. 
In my view, although the claim is not without merit, especially when it comes to business innovation, it overlooks the synergistic relationship between individual effort and teamwork, particularly with respect to scientific innovations.

With respect to business innovation, I agree that it is the vision and commitment of key individuals--such as a firm's founder or chief executive--from which businesses burgeon and innovative products, services, and marketing and management strategies emerge. 
One notable example involves the Apple Computer &bade following the departure of its founding visionary Steve Jobs. It wasn't until Jobs reassumed the helm, once again injecting his unique perception, insight, and infectious fervor, that the ailing Apple was able to resume its innovative ways, thereby regaining its former stature in the computer industry. 
Admittedly, the chief executives of our most successful corporations would no doubt concede that without the cooperative efforts of their subordinates, their personal visions would never become reality. 
Yet, these efforts are merely the carrying out of the visionary's marching orders.

Nevertheless, the speaker would have us accept a too-narrow and distorted view of how innovation comes about, particularly in today's world. 
Teamwork and individual enterprise are not necessarily inconsistent, as the speaker would have us believe. 
Admittedly, if exercised in a self-serving manner--for example, through pilfering or back stabbing--individual enterprise and energy can serve to thwart a business organization's efforts to innovate. 
However, if directed toward the firm's goals these traits can motivate other team members, thereby facilitating innovation. In other words, teamwork and individual enterprise can operate synergistically to bring about innovation.

We must be especially careful not to understate the role of teamwork in scientific innovation, especially today. 
Important scientific innovations of the previous millennium might very well have been products of the epiphanies and obsessions of individual geniuses. 
When we think of the process of inventing something great we naturally conjure up a vision of the lone inventor hidden away in a laboratory for months on end, in dogged pursuit of a breakthrough. 
And this image is not entirely without empirical support. For example, Thomas Edison's early innovations--including the light bulb, the television, and the phonograph--came about in relative isolation, and solely through his individual persistence and commitment.
However, in today's world, sdentific innovation requires both considerable capital and extensive teams of researchers. 
Admittedly, in all likelihood we will continue to encounter the exceptional case---~ke Hewlett and Packard, or Jobs and Wozniak, whose innovations sprang from two-man operations. 
But for the most part, scientific breakthroughs today typically occur only after years of trial-and-error by large research teams. 
Even Thomas Edison relied more and more on a team of researchers to develop new innovadons as his career progressed. 
Thus the statement flies in the face of how most modern scientific innovations actually come about today.

To sum up, I agree that, when it comes to the world of business, true innovation is possible only through the imagination of the individual visionary, and his or her commitment to see the vision through to its fruition. 
However, when it comes to scientific innovation, yesterday's enterprising individuals have yielded to today's cooperative research teams--a trend that will no doubt continue as scientific research becomes an increasingly expensive and complex undertaking.






The speaker maintains that the function of art is to "upset" while the function of science is to "reassure," and that it is in these functions that the value of each lies. In my view, the speaker unfairly generalizes about the function and value of art, while completely missing the point about the function and value of science.
Consider first the intent and effect of art. In many cases artists set about to reassure, not to upset. 
Consider the frescos of Fra Angelico and others monks and nuns of the late medieval period, who sought primarily through their representations of the Madonna and Child to reassure and be reassured about the messages of Christian redemption and salvation. 
Or consider the paintings of impressionist and realist painters of the late 19th Century. Despite the sharp contrast in the techniques employed by these two schools, in both genres we find soothing, genteel, pastoral themes and images---certainly nothing to upset the viewer.

In other cases, artists set about to upset. For example, the painters and sculptors of the Renaissance period, like the artists who preceded them, approached their art as a form of worship. 
Yet Renaissance art focuses on other Christian images and themes--especially those involving the crucifxiion and apocalyptic notions of judgment and damnation--which are clearly "upsetting" and disconcerting, and clearly not reassuring. 
Or consider the works of two important 20th-Century artists; few would argue that the surrealistic images by Salvador Dali or the jarring, splashy murals by abstract painter Jackson Pollock serve to "upset," or at the very least disquiet, the viewer on a visceral level.

When it comes to the function and value of science, in my view the speaker's assertion is simply wrongheaded. 
The final objective of science, in my view, is to discover truths about our world, our universe, and ourselves. 
Sometimes these discoveries serve to reassure, and other times they serve to upset. 
For example, many would consider reassuring the various laws and principles of physics which provide unifying explanations for what we observe in the physical world.
 These principles provide a reassuring sense of order, even simplicity, to an otherwise mysterious and perplexing world.

On the other hand, many scientific discoveries have dearly "upset" conventional notions about the physical world and the universe. 
The notions of a sun-centered universe, that humans evolved from lower primate forms, and that time is relative to space and motion, are all disquieting notions to anyone whose belief system depends on contrary assumptions. 
And more recently, researchers have discovered that many behavioral traits are functions of individual neurological brain structure, determined at birth. 
This notion has "upset" many professionals in fields such as behavioral psychology, criminology, mental health, and law, whose work is predicated on the notion that undesirable human behavior can be changed--through various means of reform and behavior modification.

In sum, the speaker over-generalizes when it comes to the function and value of art and science both of which serve in some cases to reassure and in other cases to upset. 
In any event, the speaker misstates the true function and value of science, which is to discover truths, whether reassuring or upsetting.







I strongly agree that by studying any particular academic discipline we alter the way we perceive the world. 
As intellectual neophytes we tend to polarize what we see as either right or wrong, or as either good or bad. 
We also tend to interpret what we see by way of our emotions. 
Once educated, we gain the capacity to see a broader spectrum of opinion and perspective, and to see our own culture and even ourselves as a tapestry-like product of history.

Through the earnest pursuit of knowledge--particularly in history and literature--we reveal to ourselves the flaws and foibles of other humans whose lives we study and read about. 
History teaches us, for example, that demagogues whom society places on pedestals often fall under the weight of their own prejudices, jealousies, and other character flaws. 
And, any serious student of Shakespeare comes away from reading King Lear and Hamlet with a heightened awareness of the tragically flawed ironic hero, and of the arbitrariness by which we distinguish our heroes from our villains.

Through education we begin to see flaws not only in people but also in ideologies that we had previously embraced on pure faith.
 A student of government and public policy learns that many of the so-called "solutions" which our legislatures and jurists hand down to us from atop their pedestals are actually Band-Aid comprises designed to appease opponents and pander to the electorate.
 A philosophy student learns to recognize logical fallacies of popular ideas and the rhetoric of our political parties, religious denominations, and social extremists. 
And, a law student learns that our system of laws is not a monolithic set of truths but rather an ever-changing reflection of whatever the society's current mores, values, and attitudes happen to be.
While education helps us see the flawed nature of our previously cherished ideas,
paradoxically it also helps us see ideas we previously rejected out of hand in a different light--as having some merit after all. 
Through education in public policy and law, once-oppressive rules, regulations, and restrictions appear reasonable constraints on freedom in light of legitimate competing interests. 
Through the objective study of different religious institutions, customs, and faiths, a student learns to see the merits of different belief systems, and to see the cultural and philosophical traditions in which they are rooted.

Education also helps us see our own culture through different eyes. As cultural neophytes we participate unwittingly in our culture's own customs, rituals, and ceremonies--because we see them as somehow sacrosanct.
 A student of sociology or cultural anthropology comes to see those same customs, rituals, and ceremonies as tools which serve our psychological need to belong to a distinct social group, and to reinforce that sense of belonging by honoring the group's traditions.
 And, by reading the literary works of writers from bygone eras, a literature student comes to see his or her own culture as a potential treasure trove of fodder for the creative literary mind. 
For example, by studying Twain's works a student learns that Twain saw 19th-Century life along the Mississippi not as a mundane existence but as a framework for the quintessential adventure story, and that we can similarly transform the way we see our own culture.

Finally, education in the arts alters forever the way we perceive the aesthetic world around us. 
Prior to education we respond instinctively, emotionally, and viscerally to the forms, colors, and sounds of art. 
Post education we respond intellectually. 
We seek to appreciate what art reveals about our culture and about humanity. 
We also seek to understand the aesthetic principles upon which true art is founded. For instance, an earnest art student learns to see not just pigments and shapes but also historical influences and aesthetic principles. 
An informed listener of popular music hears not just the same pleasing sounds and pulsating rhythms as their naive counterparts, but also the rhythmic meters, harmonic structure, and compositional forms used by the great classical composers of previous centuries, and which provided the foundation of modern music.

To sum up, through education we no longer see our heroes, leaders, and idols through the same credulous eyes, nor do we see other humans and their ideas through the black-and-white lens of our own point of view.
 In the final analysis, through education we come not only to perceive the world differently but also to understand the subjective, and therefor changeable, nature of our own perceptions.







The speaker asserts that many laws are ineffective in solving society's problems because moral behavior cannot be legislated. 
I agree with this assertion insofar as it relates to constraints on certain personal freedoms. 
However, when it comes to the conduct of businesses, I think that moral behavior not only can but must be legislated for the purpose of alleviating societal problems.


Morality laws that impinge upon freedom of choice about our personal lives--to control what we do with and to ourselves--simply do not work in a democratic society. 
People always find ways to circumvent such laws, which ultimately give way to more lenient laws that acknowledge personal freedom of choice. 
The failed Prohibition experiment of the 1930s is perhaps the paradigmatic example of this. 
And we are slowly learning history's lesson, as aptly demonstrated by the recognition of equal rights for same-sex partners, and current trends
toward legalization of physician-assisted suicide and the medicinal use of marijuana.
 In short, history informs us that legislating morality merely for morality's sake simply does not work.

Morality laws impinging on personal freedoms are not made any more useful or effective by purporting to serve the greater good of society, because on balance their costs far outweigh their benefits. 
For instance, those who defend the cfiminalization of drug use cite a variety of harms that result from widespread addiction: increased incidence of domestic violence, increased burden on our health-care and social-welfare systems, and diminished productivity of addicts. 
However, these defenders overlook the fact that outlawing addictive substances
does not prevent, or even deter, people from obtaining and using them.
 It only compels users to resort to theft and even violent means of procuring drugs, adding to the economic costs of enforcement, prosecution, and punishment. 
In short, the costs of proscription outweigh the benefits.

In sharp contrast to personal behavior, the behavior of businesses can and must be
controlled through legislation. 
Left unfettered, businesses tend to act on behalf of their own financial interest, not on behalf of the society at large. 
And when excessive business profits accrue at the expense of public health and safety, in my view business has behaved immorally.

Examples of large-scale immoral behavior on the part of businesses abound. 
For example, although technology makes possible the complete elimination of polluting emissions from automobiles, auto manufacturers are unwilling to voluntarily make the short-term sacrifices necessary to accomplish this goal. 
Tobacco companies have long known about the health hazards of smoking cigarettes; yet they weigh the costs of defending law suits against the profit from cigarette sales, and continue to cater to nicotine addicts. 
And when given the chance, many manufacturers will exploit underage or underprivileged workers to reduce labor costs, thereby enhancing profits. 
In short, only government holds the regulatory and enforcement power to impose the standards needed to ensure moral business behavior.

In sum, whether legislating morality is effective or even appropriate depends on whether the behavior at issue involves personal freedom or public duty. 
Legislating personal moral behavior is neither practicable nor proper in a democratic society. 
On the other hand, legislating business morality is necessary to ensure public health and safety.







I strongly disagree that personality is the key to how a student or scholar interprets the material with which he or she works. 
Whether those materials be facts, events, data, observations, in my view the key factor in their interpretation is a person's training and educational background.

Assuming that by personality the speaker embraces such personal attributes as individual temperament, disposition and general mood, and outlook, it seems to me that personality has little bearing on how students and scholars interpret the materials with which they work. 
Admittedly, whether an individual tends to be an optimist or a pessimist might have some beating on interpretation. 
For instance, an archeology student with a generally sanguine outlook toward life might respond to a lengthy yet unsuccessful search for certain artifacts as discovery and progress--insofar as certain possibilities have been eliminated, bringing us closer to affirmative discoveries.
 In contrast, an archeology student with a generally pessimistic outlook might condude that the same effort was in vain and that nothing has been learned or otherwise gained. 
Yet it strikes me that these reactions are emotional ones that have nothing to do with intellectual interpretation.

In sharp contrast, one's educational background and training can serve as a strong influence on how one interprets historical events involving human affairs, statistical data, and especially art. 
With respect to human affairs, consider the centuries-old imperialist policies of Great Britain. 
A student of political science might interpret British imperialism as a manifestation of that nation's desire for political power and domination over others.
 A student of economics might see it as a strategy to gain control over economic resources and distribution channels for goods.
 A sociology or anthropology student might see it as an assimilation of culture. 
And, a student of theology or religion might interpret the same phenomenon as an attempt, well intentioned or otherwise, to proselytize and to impose certain beliefs, rituals, and customs on others.

Educational training and background also affects how students and scholars interpret seemingly objective statistical data.
 It is crucial here to distinguish between numbers themselves, which are not subject to varying interpretations, from what the numbers signify--that is, what conclusions, prescriptions, or lessons we might come away with. 
Consider, for example, a hypothetical increase in the rate of juvenile crime in a particular city. Although the percent change itself might be subject to only one reasonable meaning, what the change signifies is open to various interpretations. 
A sociologist might interpret this data as an indication of deteriorating family unit or community. 
A student of public policy or government might see this statistic as an indication that current legislation fails to implement public policy as effectively as it could.
 And a student of law or criminal justice might interpret the same statistic as a sign of overburdened courts or juvenile detention facilities

Finally, when it comes to how students and scholars interpret art, training and educational background play an especially significant role. 
After all, while facts and figures are to some extent objective, the meaning Of art is an inherently subjective, and highly personal, matter. 
A business student might interpret a series of art works as attempts by the artist to produce viable products for sale in the marketplace. 
However, a theology student might eschew such a cold and cynical interpretation, seeing instead an expression of praise, a celebration of life, a plea for grace, or a struggle to come to terms with mortality. 
Even art students and scholars can interpret the same art differently, depending on their training. 
A student of art history might see a particular work as the product of certain artistic influences, while a student of art theory, composition, and technique might view the same work as an attempt to combine color for visual impact, or as an experiment with certain brush-stroke techniques.

To sum up, I concede that as students and scholars our working "materials"--facts, data, objects, and events--are open to subjective interpretation in terms of what they teach us. 
However, what our materials teach us is a function of what we've already learned, and has little if anything to do with our personal basket of emotions and moods called "personality."
 





Does knowledge render things more comprehensible, or more complex and mysterious?
 In my view the acquisition of knowledge brings about all three at the same time. This paradoxical result is aptly explained and illustrated by a number of advances in our scientific knowledge.

Consider, for example, the sonar system on which blind bats rely to navigate and especially to seek prey. 
Researchers have learned that this system is startlingly sophisticated. 
By emitting audible sounds, then processing the returning echoes, a bat can determine in a nanosecond not only how far away its moving prey is but also the prey's speed, direction, size and even specie!
 This knowledge acquired helps explain, of course, how bats navigate and survive. Yet at the same time this knowledge points out the incredible complexity of the auditory and brain functions of certain animals, even of mere humans, and create a certain mystery and wonder about how such systems ever evolved organically.

Or consider our knowledge of the universe.
 Advances in telescope and space-exploration technology seem to corroborate the theory of a continually expanding universe that began at the very beginning of time with a "big bang." 
On one level this knowledge, assuming it qualifies as such, helps us comprehend our place in the universe and our ultimate destiny. 
Yet on the other hand it adds yet another chapter to the mystery about what existed before time and the universe.
Or consider the area of atomic physics. 
The naked human eye perceives very little, of course, of the complexity of matter. To our distant ancestors the physical world appeared simple--seemingly comprehensible by means of sight and touch. 
Then by way of scientific knowledge we learned that all matter is comprised of atoms, which are further comprised of protons, neutrons, and electrons. 
Then we discovered an even more basic unit of matter called the quark. 
And now a new so-called "string" theory posits the existence of an even more fundamental, and universal, unit of matter. 
On the one hand, these discoveries have rendered things more comprehensible, by explaining and reconciling empirical observations of how matter behaves. 
The string theory also reconciles the discrepancy between the quantum and wave theories of physics. 
On the other hand, each discovery has in turn revealed that matter is more complex than previously thought. 
In fact, the string theory, which is theoretically sound, calls for seven more dimensions---in addition to the three we already know about! I'm hard-pressed to imagine anything more complex or mysterious.

In sum, the statement overlooks a paradox about knowledge acquired, at least when it comes to understanding the physical world.
When through knowledge a thing becomes more comprehensible and explainable we realize at the same time that it is more complex and mysterious than previously thought.






Is it a "grave mistake" to theorize without data, as the speaker contends? 
I agree insofar as to theorize before collecting sufficient data is to risk tainting the process of collecting and interpreting further data. 
However, in a sense the speaker begs the question, by overlooking the fact that every theory requires some data to begin with.
 Moreover, the claim unfairly ignores equally grave consequences of waiting to theorize until we obtain too much data.

In one important respect I agree with the speaker's contention. 
A theory conjured up without the benefit of data amounts to little more that the theorist's hopes and desires-- what he or she wants to be true and not be true. Accordingly, this theorist will tend to seek out evidence that supports the theory, and overlook or avoid evidence that refutes it. 
One telling historical example involves theories about the center of the Universe. Understandably, we ego-driven humans would prefer that the universe revolve around us.
 Early theories presumed so for this reason, and subsequent observations that ran contrary to this ego-driven theory were ignored, while the observers were scorned and even vilified.

By theorizing before collecting data the theorist also runs that risk of interpreting that data in a manner which makes it appear to lend more credence to the theory than it actually does. 
Consider the theory that the Earth is flat. 
Any person with a clear view of the horizon must agree in all honesty that the evidence does not support the theory. 
Yet prior to Newtonian physics the notion of a spherical Earth was so unsettling to people that they interpreted the arc-shaped horizon as evidence of a convex, yet nevertheless "flattish," Earth.

Despite the merits of the speaker's claim, I find it problematic in two crucial respects.
 First, common sense informs me that it is impossible to theorize in the first place without at least some data. 
How can theorizing without data be dangerous, as the speaker con tends, if it is not even possible? 
While a theory based purely on fantasy might ultimately be born out by empirical observation, it is equally possible that it won't.
 Thus without prior data a theory is not worth our time or attention. 
Secondly, the speaker's claim overlooks the inverse problem: the
danger of continuing to acquire data without venturing a theory based on that data. 
To postpone theorizing until all the data is in might be to postpone it forever. 
The danger lies in the reasons we theorize and test our theories: to solve society's problems and to make the world a better place to live. 
Unless we act timely based on our data we render ourselves impotent. 
For example, governments tend to respond to urgent social problems by establishing agencies to collect data and think-tanks to theorize about causes and solutions. 
These agencies and think-tanks serve no purpose unless they admit that they will never have all the data and that no theory is foolproof, and unless timely action is taken based on the best theory currency available--before the problem overwhelms us.

To sum up, I agree with the speaker insofar as a theory based on no data is not a theory but mere whimsy and fancy, and insofar as by theorizing first we tend to distort the extent to which data collected thereafter supports our own theory. Nevertheless, we put ourselves in equal peril by mistaking data for knowledge and progress, which require us not only to theorize but also to act upon our theories with some useful end in mind.







Are scandals useful in calling our attention to important problems, as this statement suggests? 
I agree that in many cases scandals can serve to reveal larger problems that a community or society should address. 
On the other hand, scandals can sometimes distract us from more important societal issues.

On the one hand, scandals can sometimes serve to call our attention to pervasive social or political problems that we would otherwise neglect. 
Perhaps the paradigmatic modern example is the Watergate scandal. 
Early in that scandal it would have been tempting to dismiss it as involving one isolated incidence of underhanded campaign tactics.
 But, in retrospect the scandal forever increased the level of scrutiny and accountability to which our public officials are held, thereby working a significant and lasting benefit to our society. 
More recently, the Clinton-Gore fundraising scandal sparked a renewed call for campaign-finance reform. 
In fact the scandal might result in the passage of a congressional bill outlawing private campaign contributions altogether, thereby rendering presidential candidates far less susceptible to undue influence of special-interest groups.
 Our society would be the dear beneficiary of such reform.
 Surely, no public speaker or reformer could have called our nation's collective attention to the problem of presidential misconduct unless these two scandals had surfaced.
On the other hand, scandals can sometimes serve chiefly to distract us from more pressing community or societal problems. 
At the community level, for example, several years ago the chancellor of a university located in my city was expelled from office for misusing university funds to renovate his posh personal residence.
 Every new development during the scandal became front-page news in the campus newspaper. 
But did this scandal serve any useful purpose? No. 
The scandal did not reveal any pervasive problem with university accounting practices. 
It did not result in any sort of useful system-wide reform. 
Rather, it was merely one incidence of petty misappropriation. 
Moreover, the scandal distracted the university community from far more important issues, such as affu'mative action and campus safety which were relegated to the second page of the campus news paper during the scandal.

Even on a societal level, scandals can serve chiefly to distract us from more
Important matters. 
For example, time will tell whether the Clinton sex scandal will benefit our political, social, or legal system. 
Admittedly, the scandal did call our attention to certain issues of federal law.
 It sparked a debate about the powers and duties of legal prosecutors, under the Independent Counsel Act, vis-i-vis the chief executive while in and out of office. 
And the various court rulings about executive privilege and immunity WIU serve useful legal precedents for the furore. 
Even the impeachment proceedings xxhll no doubt provide useful procedural precedent at  effects of the scandal in terms of the financial expense to taxpayers and the various harms to the many individuals caught up in the legal process---outweigh these benefits. 
More importantly, for more that a year the scandal served chiefly to distract us from our most pressing national and global problems, such as the Kosovo crisis, our social-security crisis, and health-care reform, to name just a few.
In sum, I agree that scandals often serve to flag important socio-political problems more effectively than any speaker or reformer can. 
However, whether a scandal works more benefit than harm to a community or society must be addressed on a case-by-case basis.







In today's world is practicality our idol---one which all powers and talents must serve. 
While this claim has considerable merit with respect to most areas of human endeavor—including education, art, and politics--I take exception with the claim when it comes to the direction of scientific research today.

Practicality seems clearly to be the litmus test for education today. 
Grade-schoolers are learning computer skills right along with reading and writing. Our middle and high schools are increasingly cutting arts education, which ostensibly has less practical value than other course work. 
And, more and more college students are majoring in technical fields for the purpose of securing lucrative jobs immediately upon graduation. 
Admittedly, many college students still advance to graduate-level study; yet the most popular such degree today is the MBA; after all, business administration is fundamentally about practicality and pragmatism that is, "getting
the job done" and paying attention to the "bottom line."

Practicality also dictates what sort of art is produced today. 
Most new architecture today is driven by functionality, safety, and cost; very few architectural masterpieces find their way past the blueprint stage anymore. 
The content of today's feature films and music is driven entirely by demographic considerations--that is, by pandering to the interests of 18-35 year old, who account for most ticket and CD sales.
 And, the publishing industry today is driven by immediate concern to deliver viable products to the marketplace. 
The glut of how-to books in our bookstores today is evidence that publishers are pandering to our practicality as well. 
It isn't that artists no longer create works of high artistic value and integrity. Independent record labels, filmmakers, and publishing houses abound today. 
It's just that the independents do not thrive, and they constitute a minuscule segment of the market. 
In the main, today's real-estate developers, entertainment moguls, and publishing executives are concerned with practicality and profit, and not with artistic value and integrity.

Practicality is also the overriding concern in contemporary politics. 
Most politicians seem driven today by their interest in being elected and reelected that is, in short-term survival rather than by any sense of mission, or even obligation to their constituency or country. 
Diplomatic and legal maneuverings and negotiations often appear intended to meet the practical needs of the parties involved minimizing costs, preserving options, and so forth. 
Those who would defend the speaker might claim that it is idealists--not pragmatists who sway the masses, incite revolutions, and make political ideology reality. 
Consider idealists such as the America's founders, or Mahatma Gandhi, or Martin Luther King. 
Had these idealists concerned themselves with short-term survival and immediate needs rather than with their notions of an ideal society, the United States and India might still be British colonies, and African-Americans might still be relegated to the backs of buses. 
Although I concede this point, the plain fact is that such idealists are far fewer in number today.

On the other hand, the claim amounts to an overstatement when it comes to today's scientific endeavors. 
In medicine the most common procedures today are cosmetic; these procedures strike me as highly impractical, given the health risks and expense involved. Admittedly, today's digital revolution serves a host of practical concerns, such as communicating and accessing information more quickly and efficiently. 
Much of chemical research is also aimed at practicality--at providing convenience and enhancing our immediate comfort. 
Yet, in many other respects scientific research is not driven toward immediate practicality but rather toward broad, long-term objectives: public health, quality of life, and environmental protection.

In sum, practicality may be our idol today when it comes to education, the arts, and politics; but with respect to science I find the claim to be an unfair generalization. Finally, query whether the claim begs the question. 
After all, practicality amounts to far more than meeting immediate needs; it also embraces long-term planning and prevention aimed at ensuring our future quality of life, and our very survival as a species.







The speaker maintains that it is easy to accept innovation and new ideas, yet difficult to accept how they are put to use. 
In my view the speaker has it backwards when it comes to socio-political ideas, at least in our democratic society. 
Nevertheless, I tend to agree with the speaker insofar as scientific innovation is concerned.

In the areas of politics and law, new ideas are not often easily accepted. 
More often than not, the status quo affords people a measure of security and predictability in terms of what they can expect from their government and what rights and duties they have under the law. 
The civil-fights movement of the 1960s aptly illustrates this point. 
The personal freedoms and rights championed by leading civil-rights leaders of that era threatened the status quo, which tolerated discrimination based on race and gender, thereby sanctioning prejudice of all kinds. 
The resulting civil unrest, especially the protests and riots that characterized the late 1960s, was dear evidence that new ideas were not welcome. 
And today those who advocate gay and lesbian rights are encountering substantial resistance as well, this time primarily from certain religious quarters.

Yet once society grows to accept these new ideas, it seems that it has an easier time accepting how they are put into practice. 
The explanation for this lies in the fact that our system of laws is based on legal precedent. 
New ideas must past muster among the government's legislative, judicial, and executive branches, and ultimately the voters, before these ideas can be codified, implemented and enforced. 
Once they've passed the test of our democratic and legal systems, they are more readily welcomed by the citizenry at large.

In contrast, consider innovations in the natural sciences. 
It seems that we universally embrace any new technology in the name of progress. Of course there are always in formed dissenters with legitimate concerns. 
For example, many scientists strongly opposed the Manhattan Project, by which nuclear warfare was made possible.
 Innovations involving alternative energy sources meet with resistance from those who rely on and profit from fossil fuels. 
Some sociologists and psychologists claim that advances in Internet technology WIU alienate society's members from one another. 
And opponents of genetic engineering predict certain deleterious social and political consequences.
Yet the reasons why these dissenters oppose certain innovations have to do with their potential applications and uses, not with the renovations themselves.
 Edward Teller, the father of the atom bomb, foresaw the benefits of atomic energy, yet understood the grave consequences of applying the technology instead for destruction.
 Innovations involving alternative energy sources meet with resistance from many businesses because of their potential application in ways that will threaten the financial interests of these businesses. 
And those who would impede advances in Internet technology fear that consumers and businesses will use the technology for crass commercialism, exploitation, and white-collar crime, rather than for the sorts of educational and communication purposes for which it was originally designed. 
Finally, opponents of genetic engineering fear that, rather than using it to cure birth defects and prevent disease, the technology will be used instead by the wealthy elite to breed superior offspring, thereby causing society's socioeconomic gap to widen even further, even resulting in the creation of a master race.

In sum, when it comes to new social and political ideas, the power and security afforded by the status quo impedes initial acceptance, yet by the same token ensures that the ideas will be applied in ways that will be welcome by our society. On the other hand, it seems that scientific innovation is readily embraced yet meets stronger resistance when it comes to applying the innovation.







Do academic and professional success both involve surviving in a new environment and eventually changing it, as the speaker claims? 
Regarding academic success, in my view the speaker overstates the significance of environment. 
Regarding professional success the speaker's threshold claim that adaptation is necessary has considerable merit; however, the extent to which professional success also entails shaping the environment in which the professional operates depends on the type of profession under consideration.

Turning fzrst to academic success, I concede that as students advance from grade school to high school, then to college, they must accustom themselves not just to new curricula but also to new environments--mompfised of campuses, classmates, teachers, and teaching methods. 
The last item among this list is proving particularly significant in separating successful students from less successful ones. 
As computers and the Internet are becoming increasing important tools for learning academic skills and for research, they are in effect transforming our learning
environment--at every educational level. 
Students who fail to adapt to this change will fred themselves falling behind the pace of their peers.

Otherwise, the speaker's prescription for academic success makes little sense. Aside from the environmental variables listed above, academia is a relatively staid environment over time.
 The key ingredients of academic success have always been, and will always be, a student's innate abilities and the effort the student exerts in applying those abilities to increasingly advanced course work. 
Besides, to assert that academic success involves changing one's environment is tantamount to requiring that students alter their school's teaching methods or physical surroundings in order to be successful students--an assertion that nonsensically equates academic study with educational reform.

Turning next to professional success, consider the two traditional professions of law and medicine. 
A practicing lawyer must stay abreast of new developments and changes in the law, and a physician must adapt to new and improved medical devices, and keep pace with new and better ways to treat and prevent diseases.
 Otherwise, those professionals risk losing their competency, and even their professional licenses. 
However, this is not to say that success in either profession also requires that the practitioner help shape the legal, medical, technological, or ethical environment within which these professions operate.
 To the contrary, undue time and energy devoted to advancing the profession can diminish a practitioner's effectiveness as such. 
In other words, legal and medical reform is best left to former practitioners, and to legislators, jurists, scientists, and academicians. 
Thus the speaker's claim unfairly overrates the ability to change one's professional environment as a key ingredient of professional success.

 In contrast, when it comes to certain other professions, such as business and scientific research, the speaker's claim is far more compelling. 
Our most successful business leaders are not those who merely maximize shareholder profits, but rather those who envision a lasting contribution to the business environment and to society, and realize that vision. 
The industrial barons and information-age visionaries of the late 19th and 20th Centuries, respectively, did not merely adapt to the winds of business and technological change imposed upon them. 
They altered the direction of those winds, and to some extent were the fans that blew those winds. 
Similarly, ultimate success in scientific research lies not in reacting to new environments but in shaping future ones--by preventing disease, inventing products that transform the ways in which we live and work, and so forth. 
Perhaps the most apt example is the field of space exploration, which has nothing to do with adapting to new environments, and everything to do with discovering them and making them available to us in the first place.

To sum up, the speaker's daim has merit insofar as any individual must adapt to new environments to progress in life and to survive in a dynamic, ever-changing world.
However, the speaker's sweeping definition of success overlooks certain crucial distinctions between academics and the professions, and between some professions and others.

